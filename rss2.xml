<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>小徐的Blog</title>
    <link>http://xuzikun.com/</link>
    
    <atom:link href="http://xuzikun.com/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>今天珍惜今天</description>
    <pubDate>Wed, 23 Nov 2022 14:52:52 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Li3DETR 读书笔记</title>
      <link>http://xuzikun.com/2022/11/23/%E3%80%8ALi3DTR%20A%20LiDAR%20based%203D%20Detection%20Transformer%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
      <guid>http://xuzikun.com/2022/11/23/%E3%80%8ALi3DTR%20A%20LiDAR%20based%203D%20Detection%20Transformer%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
      <pubDate>Wed, 23 Nov 2022 14:34:07 GMT</pubDate>
      
        
        
      <description>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referre</description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><meta name="referrer" content="no-referrer" /><h1id="li3detr-a-lidar-based-3d-detection-transformer 读书笔记">《Li3DeTr: ALiDAR based 3D Detection Transformer》读书笔记</h1><p>原文信息：[1]</p><p>G. K. Erabati 和 H. Araujo, 《Li3DeTr: A LiDAR based 3D DetectionTransformer》. arXiv, 2022 年 10 月 27 日. doi: <ahref="https://doi.org/10.48550/arXiv.2210.15365">10.48550/arXiv.2210.15365</a>.</p><p>[TOC]</p><h2 id="快速了解">快速了解</h2><p>受 DETR 在目标检测领域取得的巨大的成功的启发，这篇文章研究了将单级 Lidar 测到的点云作为输入，输出 3Dbounding box 的 end-to-end 的方法。</p><p>框架的 encoder 部分分别使用稀疏卷积(sparseconvolution)和多尺度可变形注意力( multi-scale deformableattention)对 LiDAR 局部和全局特征进行编码。<strong style="color:#ff0000;">（作者原文插了一嘴：基于稀疏神经网络的体素特征提取是有利的，（可能这里的有利是指计算负载小一点？）但它不能在有限的感受野中提取丰富的语义信息。所以才加上了multi-scale deformable attention）</strong></p><p><strong style="color:#00b050;">(文章这里还提到一个信息，说把找到框框的问题视为集合预测的问题，最早好像是 Object-DGCNN 提出来的，而不是 DETR，所以后面作者做比较的时候，也和 Object-DGCNN 做了比较)</strong></p><p>decoder 部分则首先利用学到的稀疏（sparse set of）的 objectquerry，在 croos-attentionblock 里面，关联了 LIDAR 的全局体素特征（从 encoder 获得）和 3D 预测。<strong style="color:#ff0000;">（这个 croos-attentionblock 是作者新加的）</strong></p><p>然后使用多头的注意力机制（ multi-head self-attention）来进行 objectquery interactions。最后这样的 decoder layer 被重复了 <spanclass="math inline">\(L_{dec}\)</span> 次来细化 object query 。</p><p>和 DETR 一样，这篇文章也使用了 set-to-setloss，在 nuScenes 数据集上超过了目前最好的使用 NMS 的方法，在 KITTI 数据集上也有着不错的表现。总之作者把这项工作做 work 了。<strong style="color:#ff0000;">（withoutbells and wistles.作者原文的 conclusion 里面用了这句话，大家可以去查查这句是什么意思，感觉做深度学习的人都很傲娇哈哈哈）</strong></p><p>最后作者提了一嘴，它使用了师生模型（ teacher and studentmode)来进行知识蒸馏（ knowledge distillation(KD)），这一个 trick 也让整个 model 的性能变得更好了一些。</p><h2 id="introduction">introduction</h2><p>作者在 introduction 里面对他的工作总结如下：</p><p><strong>我们提出了一种端到端、单级基于 LiDAR 的 3D 检测变换器（Li3DeTr）网络，以预测自动驾驶的 3D 边界框。</strong></p><p><strong>首先，使用 SECOND[47]通过利用稀疏卷积和 BEV 变换或使用 PointPillars 来提取体素特征。其次，我们使用具有多尺度可变形注意力的编码器模块 [55] 来捕获 BEV 特征图中的丰富语义特征和长距离依赖性，以生成 LiDAR 全局特征。</strong></p><p><strong>LiDAR 全局特征被传递到解码器模块。最后，我们在解码器中引入了一个新的 Li3DeTr 交叉关注块，以利用学习到的对象查询将 LiDAR 全局特征链接到 3D 对象预测。对象查询在多头自我关注块中彼此交互。迭代地细化对象查询，并在每个解码器层中回归 3D 边界框参数。受 DETR 的启发，我们使用集到集损失来优化我们的网络。</strong></p><p>他认为他的贡献主要在于：</p><ol type="1"><li>他做的很 work，并且吸收了 DETR 的优点，用到了 Lidar 上面。</li><li>他们提出的这个 cross atteention block 很有用，利用 objectquerry 将 LiDAR 全局编码特征与 3D 对象预测相链接。并且他们做了消融实验（ablationstudy）来验证。</li><li>他们把代码发出来了，方便后续研究。</li></ol><h2 id="related-work">Related Work</h2><p>作者在这里主要介绍了三种东西，第一种是基于点的方法，第二种是基于栅格的方法，第三种是基于 transfomer 的方法。</p><p>作者对于第一种方法的评价是：尽管基于点的方法通过集合抽象层实现了大的接受域，但它们在计算上很昂贵。</p><p>第二种：3DCNN 的方法（将点投影到规则网格）在计算上非常昂贵，并且需要大量内存，为了缓解这个问题，人们使用稀疏的 3D 神经网络进行有效的体素处理。另外一种方法是将体素特征投影到 BEV 空间，最后预测 BEV 空间中的 3D 边界框。由于这种方法利用了体素和 BEV 空间的优势，作者使用 SECON 测试了我们的网络。</p><p>第三种：作者提到了 DETR 的贡献性和开创性，然后 3DETR（前面的一些工作）是纯粹基于点的，为了自动驾驶的计算效率，本文是基于体素的，并关注 BEV 全局体素特征。</p><p>最后作者说：我们使用基于体素 BEV 的 CNN 主干架构来构建我们的模型，用于局部特征提取，使用基于注意力的架构来进行全局特征提取，以增加感受野大小，最后使用transformer decoder head 来链接全局特征和 3D 预测。</p><h2 id="methodology">Methodology</h2><p>整个网络的框架如下图所示：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211232141960.png" alt="image-20221123214134625" style="zoom:67%;" /></p><h3 id="backbonelocal-features">Backbone:Local features</h3><p>文中为了加速大规模点云的 3D 对象检测，我们将点分散到 BEV 网格中<strong style="color:#92d050;">（作者认为采用 BEV 网格，这不仅是因为 2D 网格状特征是准确度和效率之间的良好权衡，而且与自动驾驶非常相关，因为地面上的每个网格单元上可能有一个对象）</strong>，并使用 CNN 提取局部点特征。</p><p>这里作者其实用了两种 pipeline：</p><p>1. 体素化 +SparseConv 计算 3D 稀疏卷积并获得局部体素特征。</p><p>空体素被零填充，稀疏体素被转换为 BEV 2D 网格状特征。</p><p>2. 将点云转换为密集 BEV 柱图，如 PointPillars 所示，柱分辨率为 [0.2，0.2，8] 米。</p><p>使用支柱特征网来转换支柱特征。最后使用 SECOND 作为 backbone 从稀疏体素或 BEV 柱特征中提取局部体素特征，并使用特征金字塔网络（FPN）对其进行进一步变换，以获得多尺度局部体素特性图</p><h3 id="encoder-global-features">Encoder: Global features</h3><p>为了从局部体素特征图获得全局体素特征，文章采用多尺度可变形注意力机制。<strong style="color:#ff0000;">（传统注意力机制会导致编码高分辨率特征图时无法接受的计算复杂性）</strong>。多尺度可变形注意力结合了可变形卷积的稀疏采样和变换器的长距离关系框架的优点。</p><p>编码器模块的输入和输出是具有相同分辨率的多尺度特征图。可变形注意力仅关注参考点周围的一小组关键采样点，从而降低了计算复杂性。</p><p>每个查询像素的可变形自关注中的参考点是其自身。每个编码器层由具有残差连接的多尺度可变形自关注和 MLP 块组成，并重复<span class="math inline">\(L_{enc}\)</span>次。从编码器提取的全局体素特征被传递到 Li3DeTr.</p><h3 id="decoder">Decoder</h3><p>解码器输入一组 object querry, <span class="math inline">\(N_q\)</span>是查询的数量，<span class="math inline">\(Q_1\)</span>是用模型权重学习的,</p><p>全局体素特征图由解码器层组成，解码器层被重复 <spanclass="math inline">\(L_{dec}\)</span> 次数以细化对象查询。</p><p>对于第一解码器层，使用单层全连接（FC）网络和 sigmoid normalization从 object querry 中编码 3D 参考点。</p><p>每个解码器层由 Li3DeTr 交叉关注块、多头自关注块和带有跳过连接的 MLP 块组成。</p><p>Li3DeTr cross-attention block 的输入是：object queries，3D referencepoints 和 LiDAR global multi-scale feature maps。</p><p><span class="math inline">\(R_{ji}\)</span> 表示参考点 <spanclass="math inline">\(r_i\)</span>到 LiDAR 全局体素特征图的尺度 j 的投影的变换。在参考点的投影位置，对比例为 j 的 LiDARBEV 特征图进行双向采样, 在每个采样特征尺度 j 处，每个 objectqueries 的关注权重 <span class="math inline">\(w_ij\)</span>由 FC 层和 sigmoid normalization 计算。</p><p>将来自多尺度特征图的采样特征相加，以获得第 i 个参考点的交叉关注特征，最终使用公式 3 更新 objectquerie。</p><h3 id="loss">Loss</h3><p>和 DETR 一样，同样使用了 set-to-setloss，同样使用了匈牙利算法来进行二分图匹配（ match predictions andground-truths），最后不同的是作者使用的是 L1 loss and focalloss<strong style="color:#ff0000;">（DETR 中用的是 L2）</strong>，分别计算边界盒回归和分类损失，给定二分匹配。</p><p>整个模型的设计到这里就说完了，还有文章最开始提到的 knowledgedistillation这个 trick，是一种模型压缩方法，已经在工业界被广泛应用。具体可以去下面的网页看看。</p><p>https://baijiahao.baidu.com/s?id=1673896462976965754&amp;wfr=spider&amp;for=pc</p><h2 id="experiments">Experiments</h2><p>反正最后作者就是说他做的很 work 啦。</p><p>“虽然 LiDAR 点云稀疏，但我们的方法不仅检测到交通锥等小物体，还有效地检测到卡车、公共汽车、建筑车辆等大尺寸物体。这可以通过编码器中主干和注意力机制的局部和全局特征图以及解码器中的交叉注意力来实现。我们的方法还能够检测一些没有标注 groundtruth 的汽车。”</p><p>然后在 objectcategroy 部分，作者提到：“我们对网络主干中的点云进行量化，并将特征图降采样为多个步长，以增加接受范围，但这会导致信息丢失，从而使我们的网络难以检测行人和障碍物等较小的物体。未来点云骨干的设计，在保持原始分辨率的同时增加接收野，将解决这个问题。”</p><p>在 Objectdistance 部分：“尽管 LiDAR 点云在距离自我车辆很远的地方是稀疏的，但我们在编码器和解码器中的注意力机制模拟稀疏点之间的远距离交互，以预测远处的物体。”</p><p>在 Object size 部分：“ ground-truth 3D boundingboxes 被分为两个子集，分别是 0m-4m，和 4m- 正无穷。本文通过注意力机制实现的远距离交互提高了检测性能。</p><p>最后作者分别对：Attention blocks，Number ofqueries，Backbones 三个模块做了消融实验，来证明它的设计每块都是有用的。在 Number ofqueries 部分，作者试出来设定在 900 个效果最 trade-off。然后在 Backbones 部分，作者试出来 VoxelNet 作为 pipeline 的效果要比 PointPillars 更好一些（大概好 5 个百分点）。</p><h2 id="conclusion">Conclusion</h2><p>最后就是结论，这个其实可以去看本 Blog 的第一部分快速了解。</p>]]></content:encoded>
      
      
      <category domain="http://xuzikun.com/categories/DL/">DL</category>
      
      <category domain="http://xuzikun.com/categories/DL/3D-Detection/">3D-Detection</category>
      
      
      <category domain="http://xuzikun.com/tags/DL/">DL</category>
      
      <category domain="http://xuzikun.com/tags/3D-Detection/">3D-Detection</category>
      
      <category domain="http://xuzikun.com/tags/Lidar/">Lidar</category>
      
      
      <comments>http://xuzikun.com/2022/11/23/%E3%80%8ALi3DTR%20A%20LiDAR%20based%203D%20Detection%20Transformer%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pointnet(++) 学习笔记</title>
      <link>http://xuzikun.com/2022/11/17/Pointnet(++)%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <guid>http://xuzikun.com/2022/11/17/Pointnet(++)%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <pubDate>Thu, 17 Nov 2022 05:47:30 GMT</pubDate>
      
        
        
      <description>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referre</description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><meta name="referrer" content="no-referrer" /><h1 id="pointnet 学习笔记">Pointnet(++)学习笔记</h1><p>[TOC]</p><h2 id="pointnet"><strong>PointNet</strong></h2><h3 id="abstract">Abstract</h3><p>本文的贡献在于不像之前的工作将点云转换为规则的三维提速网格或图像集合，而是直接以点的形式处理点云，并且很好的尊重了点云的排列不变性。</p><p>在这方面的探索，Pointnet 的工作是开创性的，而且它简洁、高效、强大。</p><p>PointNet 所作的事情就是：对点云做特征学习，并将学习到的特征去做不同的应用：分类（shape-wisefeature）、分割（point-wise feature）等。</p><p>PointNet 之所以影响力巨大，就是因为它为点云处理提供了一个简单、高效、强大的特征提取器（encoder），几乎可以应用到点云处理的各个应用中，其地位类似于图像领域的 AlexNet。</p><p><strong style="color:#ffff00;">（当然，Alexnet 带来的影响过了几年人们又觉得有一部分可能是不太好的，但是探索开创的意义重大）</strong></p><h3 id="introduction">Introduction</h3><p>典型的卷积架构需要高度规则的数据格式，以便执行权重共享和其他内核优化的工作。但是这种数据表示转换使生成的数据变得不必要的庞大，并且会掩盖数据的自然不变量（naturalinvariances）。</p><p>网络的关键部分是使用了单个对称函数：Max Pooling。</p><p>点云的输入格式每个点都独立变换，所以很容易应用刚性或仿射变换。文中添加一个依赖于数据的空间转换器网络，该网络尝试在 PointNet 处理数据之前将数据规范化，从而进一步改进结果。</p><p>（这里就是指后文架构中的 T-Net）</p><p>PointNet 对输入点的小扰动以及通过点插入（异常值）或删除（丢失数据）导致的损坏具有高度鲁棒性。（这一点原因会在后面分析）</p><h3 id="related-work">Related Work</h3><p>分别介绍了点云特征、在 3D 数据上的深度学习的方法、在无序数据上的深度学习的方法。</p><p>点云或者 mesh，大多数研究人员都是将其转化成 3D 体素或者多视图来做特征学习的，这其中的工作包括了 VoxelNet,MVCNN 等。这些工作都或多或少存在了一些问题。</p><p>直接对点云做特征学习也不是不可以，但有几个问题需要考虑：</p><p>特征学习需要对点云中各个点的排列保持不变性、特征学习需要对 rigidtransformation 保持不变性等。虽然有挑战，但是深度学习强大的表征能力以及其在图像领域取得的巨大成功，因此是很有必要直接在点云上进行尝试的。</p><h3 id="problem-statement">Problem Statement</h3><p>本文设计了一个直接使用无序点集作为输入的深度学习框架 Pointnet。点云表示为一组 3D 点$ {Pi|i=1，…，n} $，其中每个点 <span class="math inline">\(P_i\)</span>是其<spanclass="math inline">\(（x，y，z）\)</span>坐标加上额外的特征通道（如颜色、法线等）的向量。</p><p>对于对象分类任务，输入点云要么直接从形状采样，要么从场景点云预分割。</p><p>Pointnet 为所有 k 个候选类输出 k 个分数。对于语义分割，输入可以是用于部分区域分割的单个对象，也可以是用于对象区域分割的 3D 场景的子体。该模型将为 n 个点和 m 个语义子类别中的每一个输出 n×m 个分数。</p><h3 id="deep-learning-on-point-sets">Deep Learning on Point Sets</h3><p>点云的几个特点：</p><ol type="1"><li>无序性 --&gt; 对称函数设计用于表征</li><li>点不是孤立的，需要考虑局部结构 --&gt; 局部全局特征结合</li><li>仿射变换无关性 --&gt; alignment network</li></ol><p>网络的架构设计如下图所示：</p><figure><imgsrc="https://gitee.com/easonxu01/blogimg/raw/master/img_lx_win/image-20221117101542832.png"alt="image-20221117101542832" /><figcaption aria-hidden="true">image-20221117101542832</figcaption></figure><ol type="a"><li>输入为一帧的全部点云数据的集合，表示为一个<spanclass="math inline">\(n \times 3\)</span>的 2d tensor，其中 n代表点云数量，3 对应 <span class="math inline">\(xyz\)</span> 坐标。</li><li>输入数据先通过和一个 T-Net 学习到的转换矩阵相乘来对齐，保证了模型的对特定空间转换的不变性。</li></ol><p>（T-Net 就是通过卷积和 max_pooling 对 batch 内各个点云提取 globalfeature，再将 global feature 降到 3×K 维度，并 reshape 成 3×3，得到 transform matrix）</p><ol start="3" type="a"><li>通过多次 mlp 对各点云数据进行特征提取后，再用一个 T-Net 对特征进行对齐, 之后再进行 mlp。（mlp 括号中的数字表示层大小。）</li></ol><p>（输入的维度是<spanclass="math inline">\(n\times3\)</span>​, 因此将点云看成是 channel 为 1 的“2D 图像”来进行处理，然后直接基于这个“2D 图像”做卷积，第一个卷积核 size 是[1,3]，正好对应的就是“2D 图像”的一行，也就是一个点（三维坐标），输出通道数是 64，因此输出张量维度应该是1×64。第二个卷积核 size 是 [1,1] ， 1∗1 卷积只改变通道数，输出张量维度是1×64）</p><ol start="4" type="a"><li>在特征的各个维度上执行 maxpooling 操作来聚合点的特征，得到最终的全局特征。</li></ol><p><strong>分割网络是分类网络的扩展。它连接全局和局部特征，并输出每点分数。</strong>无论是分类还是分割，本质上都还是分类任务，只是粒度不同罢了。</p><p>该网络根据任务的不同（分类还是分割）可以看成两个网络，一是做 <strong> 分类任务 </strong> 的蓝色区域，二是做 <strong> 分割任务 </strong> 的浅黄色区域，这在图上已经很明显了。</p><p>分类网络设计 global feature，分割网络设计 point-wise feature</p><p>两者都是为了让表征尽可能 discriminative，也就是同类的能分到一类，不同类的距离能拉开</p><ol start="5" type="a"><li>对分类任务，将全局特征通过 mlp 来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过 mlp 得到每个数据点的分类结果。</li></ol><p><strong>网络包含 3 个关键组件，分别对应解决上面提到的点的 3 个特征</strong></p><p><strong>a. max-pooling。作为对称函数（Symmetry Function）来解决无序性</strong></p><p>为了保证网络对输入序列的不变性，本文采用了 maxpooling 作为对称函数，也就是说，无论输入的顺序是怎样的，maxpooling 都会得到相同的结果。</p><p>（对称函数是离散数学中的一个概念。）</p><p>作者希望对变换后的元素应用对称函数，从而估计得到一个定义在点集上的一般函数：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img_lx_win/image-20221117104356332.png" alt="image-20221117104356332" style="zoom:67%;" /></p><p>我们的目标：左边 f 是我们的目标，右边 g是我们期望设计的对称函数。由上公式可以看出，基本思路就是对各个元素（即点云中的各个点）使用h 分别处理，在送入对称函数 g 中处理，以实现排列不变性。</p><p>文章通过 mlp 习得 h，用一个单变量函数（single variable function）和 maxpooling 函数习得 g。通过不同的 h，可以习得表征不同属性的多个 f。</p><p>(理解：上面这部分到底在说一件什么事情呢。maxpooling 是在经过了几次特征提取（mlp）之后使用的，上面式子中的 h 可以简单理解为提取的特征，比如颜色。不同的点的颜色特征的值是不同的，g(maxpooling)就是要综合考虑所有点的颜色属性，得出一个总体的属性 f。比如大部分点都是黑色的，那经过 g 之后，就可以得到全局的颜色表现为黑色。</p><p>当有多种 h(特征提取)时，就可以通过 h 来获得多个全局的特征，然后利用这个来分类。网络在最后提取了 1024 个特征（<span class="math inline">\(n\times1024\)</span>)做完 maxpooling 后剩余 1*1024 个特征，文章提到，特征多能够减小误差，因为在作者看来，使用对称函数的过程本身就是拟合一个标准函数的过程，特征越多，拟合的结果就接近真实函数。)</p><p><strong>b. 局部和全局信息聚合结构。</strong></p><p>这部分比较容易理解。得到的 <spanclass="math inline">\(1\times1024\)</span> 的 globalfeature 只能用来表示全局特征，用来做分类。如果做分割，就必须要有 point-wisefeature，如上图，最后分割的 feature 应该是 maxpool 后的 <spanclass="math inline">\(1\times1024\)</span>再乘 n（表示 n 个点的 1024 维，但此时 n 个点的这 1024 维的值都是一样的，因为经过了 maxpool）加上之前的<span class="math inline">\(n\times64\)</span>（这个是局部特征），这样加起来就是 <spanclass="math inline">\(n\times1088\)</span>，也就包含局部和全局特征了。</p><p>这时候的 feature 就同时包含了局部和全局的特征。</p><p>这一套下来，作者一直在做点之间特征的单独提取，除了最后一层 maxpool 获取全局信息外，并没有将点与其周围点进行融合，提取局部特征。</p><p>的确，在 PointNet 这篇文章中确实没有做到像 CNN 那样 <strong> 逐层提取局部特征。</strong>我们知道在 CNN 中，一个点会与周围若干点进行加权求和（具体取决于卷积核大小），然后获取一个新的点，随着网络层数加深，深层网络的一个点对应原始图像的一个映射区域，这就是 <strong> 感受野 </strong> 的概念。但是本文做的特征提取都是点之间独立进行的，这势必会造成一些问题，至于具体的问题解决，作者在 PointNet++ 展开了说明。</p><p><strong>c.两个联合的对齐网络，用来对齐输入的点和点特征来解决不变性</strong></p><p>这要从点云数据的 <strong> 不变性 </strong> 说出，也就是说点云数据所代表的 <strong> 目标 </strong> 对某些空间转换应该具有不变性，如旋转和平移等刚体变换。为了保证变换下的不变性，作者在提取特征之前，先对点云数据进行对齐。</p><p>直接的思路：将所有的输入点集对齐到一个统一的点集空间</p><p>对齐操作是通过训练一个小型的网络来得到<spanclass="math inline">\(3*3\)</span>转换矩阵（T-net，由点独立特征提取，最大池化和全连接层的基本模块组成），并将其和输入的点云数据相乘来实现，相当于一个预处理。作者的思路应该是经过统一的变换，原本无序的点就相当一变换到了一个统一的空间里。因为会有数据增强的操作存在，这样做可以在一定程度上保证网络可以学习到变换无关性。</p><p>特征空间的对齐也可以这么做，在点特征上插入另一个对齐网络，并预测特征转换矩阵，以对齐来自不同输入点云的特征。但是需要注意：</p><p>特征空间中的变换矩阵具有比空间变换矩阵高得多的维数，这大大增加了优化的难度。但是作者发现如果这个矩阵约等于一个正交矩阵，那么优化就方便很多，也稳定很多。为了实现这个矩阵约等于一个正交矩阵，根据正交矩阵的性质，即 <strong> 正交矩阵与其转置的乘积等于单位矩阵</strong>。那么作者在 softmax 训练损失中额外增加了一个损失函数，定义如下：其中 A 是由微型网络预测的特征对齐矩阵</p><figure><imgsrc="https://gitee.com/easonxu01/blogimg/raw/master/img_lx_win/image-20221117110835091.png"alt="image-20221117110835091" /><figcaption aria-hidden="true">image-20221117110835091</figcaption></figure><p>这样得到的正交变换不会丢失输入中的信息，从而使得特征空间的变换矩阵 A 尽可能接近正交矩阵。</p><p>文章中作者通过消融实验，也印证了 alignment network 的效果。</p><h3 id="conclusion">conclusion</h3><p>PointNet 之所以影响力巨大，并不仅仅是因为它是第一篇，更重要的是它的网络很简洁（简洁中蕴含了大量的工作来探寻出简洁这条路）却非常的 work，这也就使得它能够成为一个工具，一个为点云表征的 encoder 工具，应用到更广阔的点云处理任务中。</p><p>MLP+maxpooling 竟然就击败了众多 SOTA，令人惊讶。另外 PointNet 在众多细节设计也都进行了理论分析和消融实验验证，保证了严谨性，这也为 PointNet 后面能够大规模被应用提供了支持。</p><h2 id="pointnet-1"><strong>Pointnet++</strong></h2><h2 id="参考链接">参考链接：</h2><p>[https://zhuanlan.zhihu.com/p/264627148]:[https://zhuanlan.zhihu.com/p/86331508]:[https://zhuanlan.zhihu.com/p/336496973]:</p>]]></content:encoded>
      
      
      <category domain="http://xuzikun.com/categories/3D-Detection/">3D-Detection</category>
      
      
      <category domain="http://xuzikun.com/tags/DL/">DL</category>
      
      <category domain="http://xuzikun.com/tags/Lidar%EF%BC%8C3D-Detection/">Lidar，3D-Detection</category>
      
      
      <comments>http://xuzikun.com/2022/11/17/Pointnet(++)%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DETR 论文精读</title>
      <link>http://xuzikun.com/2022/11/15/DETR%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <guid>http://xuzikun.com/2022/11/15/DETR%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <pubDate>Tue, 15 Nov 2022 09:09:39 GMT</pubDate>
      
        
        
      <description>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referre</description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><meta name="referrer" content="no-referrer" /><h1 id="detr 论文精读 eccv20-transfomer 目标检测">DETR 论文精读 (eccv20Transfomer+ 目标检测 )</h1><p>[^9000+stars，very good]:</p><p> 简介：end-to-end 的里程碑意义很大，因为以前的目标检测领域很少有 end-to-end 的方法，大部分方法都需要一个后处理的操作，即 nms（non-maxinumsuppersion，非极大值抑制），无论是 proposal based 的方法，还是 anchorbased 的方法，还是 anchorfree 的方法，最后都会生成很多预测的框框。nms 的作用就是去掉这些框框，这些框框也会对模型的调参和部署产生一些影响。而且 nms 这个操作也不是所有硬件都支持的。</p><p> 而 DETR 解决了上面提到的这些痛点，既不需要 proposal，也不需要 anchor，直接利用 transfomer 全局建模的能力，把目标检测看成了集合预测的问题，也不会输出那些冗余的框框。把目标检测任务做到了和图像分类一样简单。（nms 和 anchor 的生成这两部分都需要不少的先验知识）</p><p>[TOC]</p><h2 id="abstract">Abstract</h2><p> 把找到框框转为集合预测的工作，听起来是很合理的设置，但是以往很少有人做的 work。</p><p> 把需要先验知识的部分去掉，例如 NMS 和 anchor的生成。最后不会出现冗余的框框，只会有一个框框。</p><p>DETR 主要提出了两个新的东西：</p><ol type="1"><li><p> 一个是新的目标函数，通过二分图匹配的方式，强制模型输出一组独一无二的预测，（每个物体理想状态下也本来就应该生成一个框框）。</p></li><li><p> 另外一个贡献就是使用了 transformer 这种 encoder-decoder 的架构，相比于最原始的 transfomer 架构，有两个小细节发生了变化：</p><ol type="1"><li><p> 一个是在 decoder 的输入部分新加入了一项，也就是文中提到的 learnedobject query，类似 anchor 的意思。</p><p>（给定这些 object query 之后，DETR 就可以把 learned objectquery 和全局图像信息结合一起，通过不停的做注意力操作，从而让模型直接输出最后的一组预测框）</p></li><li><p> 串行改为并行 </p><p> 想法 &amp;&amp; 实效性：并行比串行更合适，并不是检测一个大物体前必须先检测一个小物体，或从左到右检测，我们希望越快越好。</p><p>（这里做出改变的原因主要是最开始的 transformer 的那篇论文的应用对象是 NLP，对于输出要求有自回归的特性，因此设计了掩码的机制，让文本从左到右一点一点输出出来，但是对于我们当前的任务，不需要这种特性，我们是一下子把所有的目标检测的框框输出出来的）。</p></li></ol></li></ol><p> 作者认为 DETR 优越的地方：</p><ol type="1"><li> 简单：不需要特殊的 DLlibrary，只要硬件支持 CNN 或者 Transformer，那么就一定支持 DETR</li><li> 性能好：在 coco 数据集上，detr 和一个训练非常好的 fasterRCNN 基线网络取得了差不多的效果，模型内存和速度也和 fasterRCNN 差不多。但实际上 2020 年的时候，coco 上最好的算法，有着 53 的 ap，而 DETR 只有 44，但是想法实在是太新颖了！</li><li> 拓展性能好：在全景分割上的任务也很好。</li></ol><h2 id="introduction">Introduction</h2><p>1、目标检测任务：对每一个感兴趣的物体，去预测一些框和物体类别，就是一个集合预测问题 </p><p>2、现在大多数好用的目标检测器，都是用间接的方式去处理集合预测问题，</p><p>（1）比如 proposal 方式（如 RCNN 系列工作：faster R-CNN、MaskR-CNN、cascade R-CNN），</p><p>（2）anchor 方式（YOLO 系列，focal loss），non-anchorbased 方法（物体中心点 center net，FCOS）.</p><p> 他们都没有直接做集合预测任务，而是设计一个替代（回归、分类）解决目标检测问题。所有这些方法性能受限于后处理操作（NMS），由于用了 anchor 和 NMS 导致检测器都非常复杂 ( 因为会生成许多冗余的框框，也就是文中提到的 nearduplicatepredictions, 所以需要加入 nms 和 anchor 进行优化 )，最后整个架构变得十分复杂，难以优化和调参 </p><p>3、端到端的思想已经在别的很多任务里大范围使用，而且使任务更加简单好用。我们不要先验知识，就是要用一个端到端网络 </p><p><strong>detr 流程（训练）：</strong></p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151925228.png" alt="image-20221115140514914" style="zoom: 67%;" /></p><p>1、CNN 提取特征 </p><p>2、特征拉直，送到 encoder-decoder 中，encoder 作用：进一步学习全局信息，为接下来的 decoder，也就是最后出预测框做铺垫。（直观的理解是，使用了 encoder-decoder 之后，图片里面每一个点（特征）和其他的点（特征）就有交互了，这样他就知道了图片中物体的分布，最终的效果就是同一个物体只应该出一个框框，而不是多个。总之，全局的特征有利于移除多余的框框）</p><p>3、decoder 生成框的输出，当你有了图像特征之后，还会有一个 objectquery（限定了你要出多少框），通过 query 和特征在 decoder 里进行自注意力操作，得到输出的框（文中是 100，无论是什么图片都会预测 100 个框）</p><p>4、loss ：二分图匹配，计算 100 个预测的框和 2 个 GroundTruth 的框的 matchingloss，决定 100 个预测框哪两个是独一无二对应到红黄色的 GT 框，匹配的框去算目标检测的 loss。决定好这个匹配关系之后，才会像普通的目标检测一样，去算一个分类的 loss，在算一个 boundingbox 的 loss。剩下的 98 个没有被匹配成功的框框，就会被标记为背景类，不会参与后面的计算）</p><p><strong> 推理 </strong></p><p>1、2、3 一致，第四步 loss 不需要，直接在最后的输出上用一个阈值卡一个输出的置信度，置信度比较大（&gt;0.7 的）保留，置信度小于 0.7 的当做背景物体 </p><p><strong> 结果 </strong></p><p>1、detr 对大物体预测很准，归功于 transformer，能进行全局建模（原来使用 anchor 的话就会受限于 anchor 大小）</p><p>2、缺陷：对小物体效果不好（多尺度、多特征，可以提高小物体的检测）</p><p>3、detr 训练很慢，500 个 epoch（coco 大多数模型一般训练几十个 epoch 就行）</p><h2 id="related-work">Related work</h2><p> 作者首先讲了集合预测问题以及之前大家都是用什么样的方法，去解决集合预测的问题。</p><p> 第二部分介绍了 transfomer 的经典架构以及 paralleldecoding 是如何实现的。</p><p> 最后介绍了目标检测的相关工作：</p><p> 根据初始猜测做预测：</p><p>1、two-stage: 初始猜测是中间的 proposal</p><p>2、one-stage: 初始猜测是 anchor 或物体中心点 </p><p> 最近有一篇论文做了详细比较，发现他们的性能和刚开始的初始猜测非常相关，怎么做后处理对性能影响至关重要 </p><p> 怎么后处理：</p><p>1、集合思想（set basedloss）：可学习的 NMS 方法、关系型网络，可以利用自注意力方法去处理物体之间的联系，得出独一无二的预测，就不需要后处理的步骤（性能较低）</p><p> 性能问题解决：人工干预：手工设计的场景特征帮助模型学习，但是 DETR 目标是想让目标检测任务更加简单，不希望用到过多人工先验知识 </p><p>2、循环检测器：（之前使用 encoder-decoder 的形式去做目标检测的工作）</p><p> 当时大家使用的都是 RNN，transfomer 还没有出来。RNN 都是自回归的模型，时效性很差，性能也不是很好。</p><p> 让 detr work 主要原因：transformer。</p><h2 id="the-detr-model">The DETR model</h2><p> 分两块：</p><p>1、基于集合的目标函数怎么做，作者如何通过二分图匹配把预测的框和 GT 框连接在一起，算得目标函数 </p><p>2、DETR 具体模型架构 </p><p> 目标函数部分 </p><p>detr 模型最后输出是一个 <spanstyle="background:#FFFFBB;"> 固定集合 </span>，无论图片是什么，最后都会输出 n 个（本文 n=100）</p><p> 问题：detr 每次都会出 100 个输出，但是实际上一个图片的 GT 的 boundingbox 可能只有几个，如何匹配？如何计算 loss？怎么知道哪个预测框对应 GT 框？</p><p> 作者的处理方法就是把这个问题转换为一个二分图匹配的问题。匈牙利算法就是解决二分图匹配问题一个成熟高效的解决方案。</p><p>scipy 包提供的 linear sumassignment 可以完成这项工作，输入就是问题的 costmatrix，输出就是最优的排列。DETR 论文里：代码也用的 linear sumassignment 函数 </p><p>a,b,c 看成 100 个预测框，x,y,z 看成 GT 框，损失矩阵未必都是正方形。</p><p> 损失矩阵的值应该放些什么？loss 包含两部分：分类 loss、出框的准确度。</p><p> 最后就是遍历所有的框框，用得到的 100 个框和 GT 的框去算最后的 loss，然后把计算得到的 loss 放到 costmatrix 里面就可以了。然后把 costmatrix 带入到匈牙利方法里面，就可以得到二分图匹配的结果。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151925428.png" alt="image-20221115144013312" style="zoom: 33%;" /></p><p> 作者实际写代码的时候做了两个改动：</p><p> 第一个是把第一项的 log 去掉了，以往的目标检测问题往往会带上 log 进行计算，作者这里是为了让前后两部分 loss 有接近的取值空间。</p><p> 第二个改动就是第二项采用的不是 L_1 的 loss 而是 L_2 的 loss。这样做是因为 L_1 的 loss 和出框的大小有关系，框越大最后得到的 loss 就容易越大。但是 DETR 用了 transfomer 这样的框架，对大物体很友好，所以特别容易给出大的框框，得到大大的 loss，不易于优化。</p><p>detr 主体网络框架（图 2：图 1 的升级版）</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151925397.png" alt="image-20221115144756426" style="zoom: 80%;" /></p><p> 真代码（简化版）</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151926792.png" alt="image-20221115145409770" style="zoom: 67%;" /></p><h2 id="experiments">Experiments</h2><p> 表 1detr 和 faster RCNN 的对比 </p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img_lx_win/image-20221115145833980.png" alt="image-20221115145833980" style="zoom:67%;" /></p><p>+ 表示用更好的训练策略 (是 DETR 使用的 trick，为了公平起见，给之前的模型也用上了，比如使用了 gluloss，使用更强的 data agumentation，训练更长的时间) 把三个模型重新训练一遍 </p><p>gflops 参数：每秒进行的浮点运算次数 </p><p>gflops 越小，模型越小，跑起来越快？X</p><p> 如果更关心速度，比较 fps</p><p><strong> 检测效果 </strong></p><p>detr 由于使用 transformer 全局建模，没有用 anchor，想检测多大物体就检测多大，所以检测大物体效果较好 </p><p>detr 框架太简单，没有多尺度特征，没有 FPN，没有复杂的目标检测头，所以在小目标检测效果不好 </p><p>encode 学到的东西：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img_lx_win/image-20221115151158907.png" alt="image-20221115151158907" style="zoom:67%;" /></p><p>decoder 学到的东西：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151708839.png" alt="image-20221115170750503" style="zoom:67%;" /></p><p>encoder 和 decoder 缺一不可，encoder 学习的是全局的特征，尽可能让物体分开，而 decoder 的部分因为前面 encoder 都已经分好了，decoder 就可以把注意力放在学习物体的边缘上，怎么更好的去区分开物体，解决遮挡的问题。</p><p><strong> 结论 </strong></p><p>objectquery 可视化（n=100，这里只有 20 个）</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img_lx_win/image-20221115151253299.png" alt="image-20221115151253299" style="zoom:67%;" /></p><p> 到底学了什么（绿色代表小的 bounding box，红色代表大的横向 boundingbox，蓝色代表大的竖向 bounding box）objectquery 和 anchor 有些像，anchor 是提前定一些 boundingbox，把预测和这些提前定好的 bounding box 对比，objectquery 是可以学习的。</p><p>100 个 objectquery 就像 100 个不同的问问题的人，每个人都有自己问问题的方式，每来一个图片这些人就上去问，如果找到了合适的答案，就把答案（对应的 boundingbox），如果没找到就返回什么都没有。</p><h2 id="conclusion">Conclusion</h2><p>DETR，好！（用 objectquery 代替了之前生成 anchor 的机制，用二分图匹配替代了之前的 nms 这一步，变成端到端的工作）</p>]]></content:encoded>
      
      
      <category domain="http://xuzikun.com/categories/3D-Detection/">3D-Detection</category>
      
      
      <category domain="http://xuzikun.com/tags/DL/">DL</category>
      
      <category domain="http://xuzikun.com/tags/3D-Detection/">3D-Detection</category>
      
      
      <comments>http://xuzikun.com/2022/11/15/DETR%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>《A comprehensive survey of LIDAR-based 3D object detection methods with deep learning for autonomous driving》读书笔记</title>
      <link>http://xuzikun.com/2022/11/15/%E3%80%8AA%20comprehensive%20survey%20of%20LIDAR-based%203D%20object%20detection%20methods%20with%20deep%20learning%20for%20autonomous%20driving%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
      <guid>http://xuzikun.com/2022/11/15/%E3%80%8AA%20comprehensive%20survey%20of%20LIDAR-based%203D%20object%20detection%20methods%20with%20deep%20learning%20for%20autonomous%20driving%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
      <pubDate>Tue, 15 Nov 2022 02:20:04 GMT</pubDate>
      
        
        
      <description>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referre</description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><meta name="referrer" content="no-referrer"><h1 id="a-comprehensive-survey-of-lidar-based-3d-object-detection-methods-with-deep-learning-for-autonomous-driving- 基于 lidar 的自动驾驶深度学习 3d 物体检测方法的综合调查 - 读书笔记">《Acomprehensive survey of LIDAR-based 3D object detection methods withdeep learning for autonomous driving》（《基于 LIDAR 的自动驾驶深度学习 3D 物体检测方法的综合调查》）读书笔记</h1><p>[TOC]</p><h2 id="section1- 引言">Section1 引言</h2><p>与摄像头相比，LiDAR 不受光照条件的限制，而且以无隐私的方式捕获数据，这使得它们在技术和道德方面都非常适合复杂的户外环境。这篇文章关注的是：<strong>基于 LiDAR 的 3D 目标检测器（仅使用 LiDAR 传感器数据，而不依赖任何其他传感器的数据）</strong></p><p>针对点云中的 3D 目标检测及其在自动驾驶中的应用已有大量研究，其他综述类文献侧重于 <strong> 自动驾驶应用中的目标检测和语义分割，以及使用多模态技术的深度学习网络。</strong></p><p><em>与前述工作相比，该综述的贡献总结如下：</em></p><p><em>1. 文章介绍了一个 <strong> 通用操作流程 </strong>，为<strong> 结构化分类 </strong> 奠定基础，便于比较并显示 <strong> 各检测器间的相似之处和不同之处。</strong></em></p><p><em>2. 文章提供了详尽的 <strong> 最新 3D 目标检测器列表 </strong>。侧重于描述每种目标检测器的<strong> 优缺点 </strong> 和其在 <strong> 操作流程上的特殊性</strong>，以确保检测结果的高效性和有效性。</em></p><p>3. 文章最终的结论确定了未来新的 3D 目标检测器设计中 <strong> 应该采用或避免的一些关键特征</strong>。</p><h2 id="section-2- 背景">Section 2 背景</h2><h3 id="激光雷达和点云">2.1 激光雷达和点云</h3><p>LiDAR 的最终输出是一组点，称为点云。每个点通常是一个 <strong> 四维向量编码 </strong>，包含 3D 坐标[x,y,z] 和激光反射强度 r，激光反射强度会反应有关物体反射表面的信息。某些 LiDAR 会用 <strong> 五维向量 </strong> 对每个点进行编码，增加一个值 e——对应于 <strong> 激光脉冲超出其标准宽度的伸长率</strong>。</p><p>LiDAR 坐标系中每个点的 3D 坐标计算如下：</p><p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="22.313ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9862.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1905.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2647.8,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(3370,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(3803,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(4288,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(4757,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5146,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(5768,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6379.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(7101.4,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(7534.4,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(8019.4,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(8488.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8877.4,0)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(9473.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p><p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="22.189ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9807.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2565.8,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(3288,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(3721,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(4206,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(4675,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5064,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(5686,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6297.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(7019.4,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(7488.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7833.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(8433.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8822.4,0)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(9418.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p><p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.749ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6077 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(742.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1798.6,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2540.8,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(3263,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(3732,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4077,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4677,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5066,0)"><path data-c="1D714" d="M495 384Q495 406 514 424T555 443Q574 443 589 425T604 364Q604 334 592 278T555 155T483 38T377 -11Q297 -11 267 66Q266 68 260 61Q201 -11 125 -11Q15 -11 15 139Q15 230 56 325T123 434Q135 441 147 436Q160 429 160 418Q160 406 140 379T94 306T62 208Q61 202 61 187Q61 124 85 100T143 76Q201 76 245 129L253 137V156Q258 297 317 297Q348 297 348 261Q348 243 338 213T318 158L308 135Q309 133 310 129T318 115T334 97T358 83T393 76Q456 76 501 148T546 274Q546 305 533 325T508 357T495 384Z"></path></g><g data-mml-node="mo" transform="translate(5688,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p><p>其中：</p><p>d 指的是测量距离</p><p>φ 指绕 Z 轴的偏航角</p><p>ω 指每个激光发射器的固定俯仰角</p><h3 id="d-bbox- 编码">2.2 3D BBox 编码</h3><p><strong>3D BBox(A three-dimensional boundingbox，三维边界框)用于定义目标在 3D 空间中的位置、大小和方向。</strong>3DBBox 具有适当的尺寸和方向来与目标紧密绑定。如果目标被部分遮挡或截断，3DBBox 调整适当的大小和位置以表示完整目标的大小。对自动驾驶而言，<strong>会假设所有物体都在地面上 </strong>，那么仅需要对<strong> 偏航角 </strong> 进行预测。<strong>3DBBox 由其 3D 中心坐标 [x,y,z]、尺寸[l,w,h] 和偏航方向θ进行编码。</strong></p><h2 id="section-3- 操作流程"><strong>Section 3 操作流程</strong></h2><p>文章提出一个基于 LiDAR 的 3D 目标检测器共通的操作流程，<strong>由三个不同的模块组成：</strong></p><p><strong>1.LiDAR</strong> <strong>SDR</strong>（LiDAR Sensor DataRepresentation LiDAR 数据的表达形式）<strong>、</strong></p><p><strong>2. 特征提取（Feature extraction）、</strong></p><p><strong>3. 核心目标检测</strong>。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151047602.png" alt="image-20221114224142246" style="zoom: 67%;"></p><p>如上图所示，</p><ol type="1"><li>在 <strong>LiDAR SDR</strong> 中，输入的 LiDAR 点云数据被转换为 <span style="background:#FFFFBB;"> 结构化且紧凑 </span> 的表达形式；</li><li>在 <strong> 特征提取 </strong> 中，上述表达形式可被提取出 <span style="background:#FFFFBB;"> 丰富的高维特征</span>；</li><li><strong>核心目标检测 </strong> 模块则负责处理 <span style="background:#FFFFBB;"> 学习到的高维特征，输出目标类别、位置、大小的预测结果</span>。</li></ol><p>核心目标检测模块由两个阶段组成：检测器网络（DetectorNetworks）和预测细化（PredictionReﬁnement）。检测器网络接收来自特征提取模块的高维特征作为输入，并输出关于目标的类别、位置和大小的3D BBox 候选框。预测细化对检测器网络中的 3DBBox 进行重新采样，提取局部特征并对其进行处理，以输出对目标位置、大小和类别最终更准确的预测。</p><p>在核心目标检测模块中仅使用检测器网络的 3D 目标检测器被称为一阶段（One-stage）检测器，检测器网络和预测细化阶段均被使用的检测器则被称为二阶段（two-stage）检测器。一阶段 <strong> 检测器在推理时速度快但精度稍逊，二阶段检测器精度高但速度慢。</strong></p><p>更详细的介绍如下</p><h3 id="lidar-sdr">3.1 LiDAR SDR</h3><p>输入的 LiDAR 数据以点云形式来表示（可来自一个或多个 LiDAR 传感器，根据车上安装的数量而定）。但是由于点云非结构化和非固定大小的特征，它不能直接被 3D 目标检测器处理，必须通过某种表达形式将其编码为更紧凑的结构，目前主要有以下五种表达形式：<strong>基于点的（point-based）、基于体素的（voxel-based）、基于支柱特征的（pillar-based）、基于投影的（projection-based）和基于图的（graph-based）</strong>。最新的检测器架构中还会用两种不同的表达形式，称之为双重表达类别。</p><p><strong style="color:#00b050;">（将无序点云排为有序点云）</strong></p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040128.jpeg" alt="img" style="zoom: 25%;"></p><h4 id="point-based"><strong>3.1.1 Point-based</strong></h4><p>输入的 LIDAR 点云数据保留了点云的非结构化形式，但当转换为固定大小时，其会变得更加紧凑。</p><p>通过随机采样和最远点采样（Furthest PointSampling，FPS）这两种不同的方法将点云从其原始大小（即大约 120k 点）采样到较小的固定大小的 N 点（即 N=16k 点）来实现的。</p><p>在随机抽样中，会随机抽取点直到选择至 N 个点为止。但随机抽样存在偏差：相较于点云稀疏区域的点，点云较密区域的点会被更频繁地采样。</p><p>FPS 算法通过迭代过程根据最远距离标准来选择点，可以减轻这种偏差。在每次迭代中，FPS 会 <strong> 先计算未采样点到点集合（第一个点随机采样，第二个点为距离第一个点最远的点）的最小距离 </strong>，然后选择距离最远的未采样点，如此循环往复，最终得到的结果是一个更具代表性的点云，<strong> 但这种方式会增加计算成本。</strong></p><h4 id="voxel-based- 体素化"><strong>3.1.2 Voxel-based体素化</strong></h4><p>体素化是将点分配给体素的过程，给定一个传入的 LiDAR 点云<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="18.438ex" height="1.984ex" role="img" focusable="false" viewBox="0 -683 8149.6 877"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(1028.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2084.6,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mn" transform="translate(503,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1003,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1447.7,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mn" transform="translate(1950.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(2450.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(2895.3,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(3340,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(3784.7,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(4229.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4674,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(5177,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></g></svg></mjx-container></span> 和 3D 空间 [<em>L,</em><em>W, H</em>] ，以此划分固定大小的体素[<em>uL, uW, uH</em>]。</p><p>根据 <strong> 笛卡尔坐标系或圆柱坐标系 </strong> 对 3D 空间进行分区，分别产生长方体或圆柱切片形状的体素。按照圆柱坐标系的体素化也被称为混合柱面（Hybrid-Cylindrical-Spherical，HCS）体素化。</p><p>如果没有点被分配给这一体素，该体素则被确定为 <strong> 零体素 </strong>，当至少有一个点分配给它时，则将其确定为<strong> 非零体素</strong>。</p><p>执行点到体素分配 / 映射的方式有三种：<strong>固定体素化（fixedvoxelization）、动态体素化（dynamicvoxelization）和混合比例体素化（hybrid scalevoxelization）。</strong></p><p><strong>固定体素化 </strong>：含两个阶段：<strong> 分组阶段和采样阶段</strong>。</p><p>分组阶段：首先，构建一个大小为 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="10.692ex" height="1.643ex" role="img" focusable="false" viewBox="0 -704 4725.9 726"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mo" transform="translate(991.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1991.4,0)"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path></g><g data-mml-node="mo" transform="translate(2976.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(3976.9,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g></g></g></svg></mjx-container></span> 的固定缓冲区，其中 V 是体素的最大数量，O 是每个体素的最大点数，F 是特征向量的大小。在分组阶段，所有点<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.878ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 830 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>根据它们的 3D 坐标会被分配给体素<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="2.166ex" height="2.211ex" role="img" focusable="false" viewBox="0 -683 957.3 977.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></svg></mjx-container></span>。</p><p>采样阶段：鉴于存在一个体素包含的点数可能多于 O 个的情况，采样阶段会从体素中随机子采样 O 个点。假设点数为 K，其中 (K&lt;O)），则将 K 个点分配给一个体素，然后在剩余的(O-K) 缓冲区索引上应用零填充。</p><p>以上方式同样适用于体素。假设非零体素的总数为 T，其中(T &gt;V)，则随机对体素进行子采样，否则，如果(T &lt; V)，则对剩余的 (V - T)缓冲区索引。</p><p><strong style="color:#00b050;">这里推荐去看原文，英文更容易理解一些。意思就是体素化的过程不仅能对点做一遍，还可以对体素再做一遍</strong></p><p>在固定体素化过程中，构建了一个固定的缓冲区大小，但是在点和体素丢失的时候也会丢失一定的信息。</p><p><strong>动态体素化：</strong>在动态体素化中，点到体素的分配策略类似于固定体素化的分组阶段，其中所有点都分配给体素。</p><p>然而，与固定体素化不同的是，没有采样阶段，因此不会预先确定 3D 空间中非零体素的最大数量 V 和每个体素的最大点数 O，这两个数字而是动态变化的。这会产生一个 <strong> 动态缓冲区 </strong> 且<strong>不会丢失任何信息</strong>，因为没有体素或点被丢弃。</p><p><strong style="color:#00b050;">即把点都收过来了，也没有做降采样</strong></p><p>点到体素的双向关系表示如下：</p><figure><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040185.png" alt="image-20221115100705122"><figcaption aria-hidden="true">image-20221115100705122</figcaption></figure><p><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.511ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2877.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(676,-150) scale(0.707)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g><g data-mml-node="mo" transform="translate(1269.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1658.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2488.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>是将每个点 pi分配给体素 vj 的映射函数</p><p><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="6.548ex" height="2.363ex" role="img" focusable="false" viewBox="0 -750 2894.4 1044.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(676,-150) scale(0.707)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g></g><g data-mml-node="mo" transform="translate(1257,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1646,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(518,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(2505.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>是在体素 vj 内收集pi 点的映射函数</p><p><strong>混合比例体素化：</strong>与动态体素化类似，3D 空间中非零体素的最大数量 V[L,W,H]和每个体素的最大点数 O 不是预先确定的，而是动态变化的。然而，<strong>仅确定了点到体素的映射函数 </strong>，因此没有建立双向映射。此外，给定一个 differ<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.73ex;" xmlns="http://www.w3.org/2000/svg" width="11.902ex" height="2.427ex" role="img" focusable="false" viewBox="0 -750 5260.8 1072.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="msubsup" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-307) scale(0.707)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mo" transform="translate(1414.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msubsup" transform="translate(1859.2,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-307) scale(0.707)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g><g data-mml-node="mo" transform="translate(3255.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msubsup" transform="translate(3699.9,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-307) scale(0.707)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mo" transform="translate(4982.8,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span> 的总数，其中 s∈{1,2,...,S}，即<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.714ex;" xmlns="http://www.w3.org/2000/svg" width="40.903ex" height="2.601ex" role="img" focusable="false" viewBox="0 -833.9 18079.3 1149.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(922.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1978.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(2478.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msubsup" transform="translate(2923.2,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(605,-300) scale(0.707)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mo" transform="translate(4337.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(5393.3,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(605,-300) scale(0.707)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g><g data-mml-node="mo" transform="translate(7067.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(8122.9,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(778,0)"></path></g><g data-mml-node="mi" transform="translate(9400.9,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(10278.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msubsup" transform="translate(10723.6,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(605,-300) scale(0.707)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mo" transform="translate(12137.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(13193.7,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(605,-300) scale(0.707)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g><g data-mml-node="mo" transform="translate(14867.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(15923.3,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(778,0)"></path></g><g data-mml-node="mi" transform="translate(17201.3,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>。在某些论文中，体素的高度对于所有比例都是固定的。点到体素映射通过一个索引 ci 确定，公式如下：</p><figure><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040930.png" alt="image-20221115100732674"><figcaption aria-hidden="true">image-20221115100732674</figcaption></figure><p>前文提到的固定体素化、动态体素化和混合比例体素化都是根据 3D 坐标将点分配给体素，在空间域中来变换 LiDAR 点云。为了完成整个体素化过程，下一步是通过 <strong> 提取体素特征 </strong> 来转换特征域中的点云。</p><p>提取体素特征有以下几种方式：</p><p>①二进制占用编码（最简单的方式），其中二进制值 0 和 1 分别分配给每个零和非零体素；</p><p>②统计方法，例如统计 3D 坐标、反射强度的平均值，甚至是形状因子；</p><p>③深度学习模型。首先，使用标准坐标、反射强度值和其他基于统计的特征来对各个点进行编码。接下来，将点引入基于 PointNet 的架构中，从而产生输出特征向量。这种架构最具代表性的例子是体素特征编码（VoxelFeature Encoding，VFE）模块，如图 3 所示。</p><figure><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040107.webp" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><center>VoxelNet 的 VFE 模块框图</center><p>从这张图可以看到的流程是：采样到的点首先进一个 MLP，然后输出一组基于点的特征；然后作者采用了一种特征连接策略：将其中一部分特征经过一个最大池化层，得到局部聚集特征，然后再和没有处理的特征连接起来；这样连接 n 层，最后得到 C 维的基于体素的特征。</p><p><strong style="color:#00b050;">A-loam 里面采用的就是基于体素的方法。</strong></p><h4 id="pillar-based 基于柱的"><strong>3.1.3Pillar-based 基于柱的</strong></h4><p>根据《Pointpillars: Fast encoders for obPject detection from pointclouds.》一文介绍，Pillar-based 这种点云表达形式 <strong> 忽略了沿 Z 轴的划分 </strong>，3D 空间<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.191ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4062.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(959,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1403.7,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(2451.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2896.3,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(3784.3,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span> 划分为固定大小的柱子<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.779ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 5206.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(850,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(1531,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1975.7,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2547.7,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(3595.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4040.3,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(4928.3,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span>。直观来讲，柱子被视为沿 Z 轴的未绑定体素。与体素化类似，将点分配给柱子是通过固定体素化、动态体素化和混合比例体素化三种不同的方式进行的。</p><p>Pillar-based 的特征的提取是通过深度学习模型，该模型受遵循 VFE 模块的 PointNet 启发而来。由于柱子没有沿 Z 轴划分，Pillar-based 的点云表达形式被视为多通道的 BEV 图像。PointPillars 这种目标检测器提出了 Pillar-based表达形式下的点云的特征提取这一过程中最具代表性的模块。</p><h4 id="projection-based- 基于投影的"><strong>3.1.4 Projection-based基于投影的</strong></h4><p>在 Projection-based 的点云表达形式中，3D 空间的点通过透视变换的方式被投影到 2D 平面中。基于投影的点云表达形式分为前视图 (FV) 和鸟瞰图(BEV)。</p><p><strong>前视图（Front-Viewprojection，FV）</strong>：点云被投影到一个球形或圆柱形表面，其原点位于 LiDAR 传感器。然后将圆球或圆柱的表面展开成 2D 平面，最终形成密集且结构化的距离图像。</p><p>初始特征的数量取决于 FV距离图像中的通道数。前视图中的像素通常由手工或预定特征进行编码，例如二进制占用编码、3D坐标、与传感器的距离、方位角或其对应点的反射强度等。</p><p><strong>鸟瞰图（Bird’s Eye View，BEV）</strong>：通过将点分配给相应的网格（一个网格可能包含多个点），将点云投影到具有一定网格分辨率的λ米的 BEV 地图中。</p><p>与前视图相似，BEV 图像的通道数决定了初始特征的数量。BEV 图像中的网格 / 像素通常是手工或根据预定特征进行编码，例如沿Z 轴固定大小分区的二进制占用编码和网格内点的统计值。</p><p><strong style="color:#00b050;">Lego-loam 采用的就是种方式，FV，点云被投影到一个圆柱形表面，预定的特征是到传感器的距离</strong></p><h4 id="graph-based- 基于图像的"><strong>3.1.5. Graph-based基于图像的</strong></h4><p>在 Graph-based 的表达形式中，<strong>点云被转换为图形 </strong>。<strong> 点被视为节点 </strong>，<strong> 一个点与其位于固定半径 d 内的其他点相连后被视为边。</strong></p><p>在原始点云的基础上使用该方法来计算非常低效，因此 <strong> 常用体素化后的采样点云来代替原始点云</strong>。</p><p>每个节点的初始特征的计算方式与中类似。首先，选择节点周围半径 d 内的一组点。通过多层感知器 (MLP) 处理其规范坐标和反射强度值，之后通过 Max-pooling 操作计算节点的初始特征向量。</p><h3 id="特征提取">3.2 特征提取</h3><p>被转换为结构化且紧凑的表达形式后，在特征提取模块可使用某些技术和架构来提取丰富的高维特征。这些技术主要分有两大类，<strong>3DBN</strong>(3DBackbone Networks)和<strong>2DBN</strong>(2D Backbone Networks)。选择何种特征提取技术会受到 LiDARSDR 形式的影响，例如将点云投影到 BEV 中后只能用 2DBN 来进行高维特征提取，不可用 3DBN。</p><h4 id="d-backbone-networks"><strong>3.2.1. 3D Backbonenetworks</strong></h4><p>根据构建模块的不同，主要有三组不同的 3DBNs。</p><ol type="1"><li>第一组是在 3D 空间中运行的 3D CNN(Convolutional Neural Networks,卷积神经网络)，</li><li>第二组是 Point-Net/PointNet++ 网络，</li><li>第三组是 GNN(Graph Neural Networks, 图神经网络)。</li></ol><p><strong>3DBNCNN：</strong>3D 卷积应用于 3D 空间中的结构化数据，例如用于自动驾驶应用的体素化点云等。但 3D 卷积的 <strong> 计算负担 </strong> 导致其无法保证实时性，进而阻碍了 3DCNN 在自动驾驶应用中的使用。研究者们进一步设计了 <strong> 空间稀疏卷积和子流形稀疏卷积网络 </strong> 以有效加速卷积操作，因此构建了 3D 稀疏(3DSpConv)和 3D 子流形稀疏 (3D Sub-SpConv) 卷积网络模型。无独有偶，文章《Votingfor voting in online point cloud object detection》的研究者演示了一种在3D 数据中应用滑动窗口（sliding window）的有效投票方案（votingscheme)。</p><p><strong style="color:#00b050;">其实在 Transfomer 的论文里面，作者也提到了这样的背景，就是 CNN 计算负载过大，人们想了很多办法来优化它，比如 3D 稀疏(3DSpConv)和 3D 子流形稀疏(3DSub-SpConv)卷积网络模型，但是 transfomer 的作者最后骄傲的说，虽然做了这些改进，但是问题还是没有解决，但是 transfomer 就没有这个问题。之后可以去看一下基于 transfomer的 DERT </strong></p><p>考虑到 LiDAR 点云的 <strong> 稀疏性</strong>（即大约 90% 的体素都没有点），Vote3Deep 使用了 <strong> 投票方案</strong>（voting scheme），而 SECOND 使用了 3DSpConv 和 3D SubSpConv 来构建基于 3D sparseCNN 的骨干网络，用于 LiDAR 点云中的 3D 目标检测。</p><p>3DBN sparseCNN 的设计遵循 encoder 网络架构或 encoder/decoder 网络架构。Encoder 网络架构会使用足够多的连续的 3DSpConv 层和 3D SubSpConv，然后是 BatchNormalization 和 Relu。<strong>输出一个缩小的、具有丰富特征的体素化 3D 空间</strong>。随后，执行高度压缩以沿 Z 轴连接特征并构建高维 BEV 特征图。encoder/decoder 网络架构与 encoder 网络架构相同，而对于 encoder 部分，使用足够多的连续的 3DSpConv 层和 3DSubSpConv，然后是 BatchNormalization 和 Relu，最终结果是一个与初始空间维度相似的上采样体素化 3D 空间，每个体素会被分配一个语义标签。encoder 和 encoder/decoder3D CNN 架构的框图如图 4 所示。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040503.webp" alt="img" style="zoom: 50%;"></p><center>两种不同 3DBN CNN 架构的框图：(a) 3D sparse CNN encoder，如 SECOND； (b)3D sparse CNN encoder/decoder，如 Parts A2 Net</center><p><strong><em>3DBNPointNet++：</em></strong>点云输入后，PointNet++ 的分割形式能够 <strong> 提取每个点的语义分割分数 </strong> 和<strong>全局的上下文特征</strong>。因此，PointNet++ 非常适合从 LiDAR 点云中提取特征。</p><p>在其语义形式中，PointNet++ 由几个遵循 encoder 网络架构的 SA(SetAbstraction，集合抽象)层和几个遵循 decoder 网络架构的 FP(FeaturePropagation,特征传播)层组成。给定初始数量的点作为质心，SA 层利用 FPS 算法在球查询区域内（围绕质心点）选择固定数量的点，然后应用 PointNet 提取局部特征向量。SA 层学习到的特征输入至 FP 层后，FP 层通过插值将学习到的多尺度特征传播回所有点。许多自动驾驶领域的 3D 目标检测器使用都 PointNet++ 作为 3DBN 来进行特征提取。</p><p>为了节省计算资源，研究者们尝试移除 FP 层。部分论文提出了仅使用 PointNet++ 的 encoder 网络架构部分。但同时为了弥补 decoder 部分的不足，PointNet++ 的 SA 层中引入了一种新的点采样算法，称为融合采样（FusionSampling,FS）。FS 是一种采样策略，它使用两种采样算法，FPS 和 Feature-FPS(F-FPS)。F-FPS 计算每个 SA 层末端的点之间的特征距离，并将其用作选择点的标准，以尝试增加前景点的选择而不是背景点。FS 样本的点一半是基于欧几里得距离（FPS），另一半基于特征距离（F-FPS），并试图在两种 FPS 算法之间找到平衡。用于 3D 目标检测的语义 3DBNPointNet++ 和 encoder/decoder 和 3DBN PointNet++ encoder的 FS 的框图如下。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040191.webp" alt="img" style="zoom:33%;"></p><center>两种不同 Backbone 3D PointNet++ 架构的框图： (a) 类似于 STD 的 3DPointNet++ 编码器 / 解码器。 (b) 3D PointNet++ 编码器架构，具有 3DSSD中的融合采样</center><p><strong>3DBNGraph:</strong>输入 Graph-based 的点云表达形式，GNN 用于通过沿边缘聚合特征来学习每个节点的特征。GNN 会执行固定数量的 T 次迭代，其中第 t 次迭代的节点特征用作第 (t+1) 次迭代的输入特征。MLP（多层感知机）和 Max 操作用于提取类似于 PointNet 的节点特征。MLP 的权重不在迭代之间共享，而是在每次迭代 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="12.971ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 5733.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(638.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(1694.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(1972.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2472.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(2917.2,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(3417.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(3861.9,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(4306.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4751.2,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(5455.2,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span> 时单独学习。</p><h4 id="d-backbone-networks-1"><strong>3.2.2 2D Backbonenetworks</strong></h4><p>2DBN 是一种全连接卷积网络 (Fully Convolutional Network，FCN)，应用于2D 空间中的结构化数据（如 BEV 和 FV距离图像）来提取丰富的高维特征图。</p><p>2DBN 有不同的架构，大致可分为以下四类：FPN(Feature PyramidNetworks，特征金字塔网络)、U-Net、ResNet 和 VGG。</p><p>其中对于遵循 FPN 架构的 2DBN，输入和输出特征图的数量并不总是相同的。因此引入以下术语：</p><ul><li>SISO：单输入，单输出（Single Input feature map, Single Outputfeature map）</li><li>SIMO：单输入，多输出（Single Input feature map, Multiple Outputfeature maps）</li><li>MIMO：多输入，多输出（Multiple Input feature maps, Multiple Outputfeature maps）</li><li>MISO：多输入，单输出（Multiple Input feature maps, Single Outputfeature map）</li></ul><p>2DBN 的构建块通常由 2D 卷积 (2D Conv) 层以及 BatchNormalization 和 Relu 组成，然而，对于某些 3D 目标检测器，2D Deformable(2DDefConv)或 2D Dilated Convolutions(2D DilConv))也适用。2D 转置卷积(2DTrConv)用于对特征图进行上采样。</p><p>下图 2DBN 最具代表性的几个架构。遵循 BEV(FPNSISO)架构的 2DBN 会执行上采样到固定大小，然后进行连接，以构建高维 BEV 特征图，VoxelNet 和 SECOND 检测器采用的这类 2DBN；遵循 FV（FPNSISO）架构的 2DBN 用于提取与输入空间维度相同的高维 FV 特征图像，RangeRCNN 检测器采用的这类 2DBN。遵循 BEV（FPNMIMO）架构的 2DBN 被用以提取多尺度的高维 BEV 特征图，分为早期和晚期融合阶段，Voxel-FPNto 检测器采用的这类 2DBN。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040344.webp" alt="img" style="zoom:50%;"></p><center>三种不同 2DBN 的框图： (a) BEV (FPN SISO) 架构，如 VoxelNet、SECOND。 (b)FV (FPN SISO) 架构，如 RangeR-CNN。 (c) BEV (FPN MIMO) 架构，如 Voxel-FPN</center><h3 id="核心目标检测">3.3 核心目标检测</h3><p>核心目标检测模块用于处理从特征提取模块中提取的 <strong> 高维特征</strong>，并以<strong>3DBBox</strong>的形式提供关于目标类别以及检测目标的 <strong> 位置和大小的分类置信度分数和回归值 </strong>。它分为两个阶段，<strong> 检测器网络和预测细化。</strong></p><h4 id="检测器网络"><strong>3.3.1 检测器网络</strong></h4><p>检测器网络有两种主要方法：<strong>Anchor-based和 Anchor-free</strong>。</p><p>Anchor-based 网络利用多个 <strong> 预定义大小的锚点 </strong> 来搜索高维特征图，输出分类分数，并相对于锚点的位置和大小回归目标的位置和大小。</p><p>Anchor-free 网络不使用预定义的锚，而是利用来自特征提取模块的二进制标签信息来识别属于目标的点或区域 / 部分。然后对于目标的每个点或部分，进行目标预测，包括一个类置信度分数和一个 3DBBox。</p><p><strong>Anchor-Based 网络</strong>：Anchor-Based网络最具代表性的架构是 RPN（Region Proposal Network，候选框提取网络）。在 3D 目标检测器中，RPN 接收一个或多个高维 BEV 特征图作为输入，输出目标的类别、3D 位置、大小和方向等。研究会使用预定好的固定大小的 3D 锚点框。锚框大小是根据每个类的自然维度来选择的，例如 KITTI 数据集中对于“汽车”类，会用 l(长)=3.9m、w（宽）=1.6m、h（高）=1.56m 的锚尺寸，而对于“行人”类，则使用 l=0.8m、w=0.6m、h=1.73m 的锚点尺寸。</p><p>输入高维 BEV 特征图之后，高效的 1x1 卷积层被应用于每个目标任务的分类、目标位置 / 大小和方向的检测，从而产生概率得分和回归图。RPN 的输出是多个 3DBBox 候选框，一般会存在多个候选框重叠并对应于同一个目标的情况。为去除多余的 3DBBox 候选框，NMS（Non MaximumSuppression，非最大抑制）则被用作后处理步骤。</p><p>另一种方法（不在 BEV 中操作）在 3D 空间中引入了球形锚的概念。对于每个点，会创建一个具有预定尺寸的球形锚，并应用 NMS 来减少锚的总数。之后在每个球形锚点上用一个 PointNet 网络来预测一个 3DBBox。最后，会使用一个额外的 NMS 来删除冗余的 3D Bbox 候选框。</p><p><strong>Anchor-Free 网络：</strong>Anchor-Free网络利用特征提取模块中的二进制标签信息来识别目标点 (部分)，并预测每个点(部分) 的 3DBBox 候选框。Anchor-Free网络分为在 3D 空间运行和在 2D 空间中运行。</p><p>对于在 3D 空间中运行的 Anchor-Free网络，一个常见的趋势是为特征提取模块中的每个点学习二进制语义标签（背景 / 前景）。然后，通过全连接 (FC) 层对每个点进行 3DBBox 预测。对于所有上述 Anchor-Free网络，每个目标（由众多前景点 / 体素组成）可能会被计算出多个候选框，因此，仍然需要 NMS 来去除冗余的 3DBBox 候选框。为了完全去除 NMS 后处理步骤，文章《Joint3D instance segmentation and object detection for autonomousdriving.》中采用的方法是将每个点的二进制语义信息以及每个点的空间嵌入（SE）信息（均从 3DBN 学习得到）提供给一个简单的聚类算法（即 K-means）来执行实例分割，因此每个实例只生成一个 3DBBox 候选框。</p><p>在 2D 空间中运行的 Anchor-Free网络，当试图利用每个前景网格的内部对象位置时，《Object as hotspots: Ananchor-free 3D object detection approach via firing ofhotspots》这篇文章中预测了两个单独的 BEV 图，一个用于前景分类，一个用于 3DBBox 回归，每个前景根据对应于目标分区的 k 类进一步编码。</p><p>受 2D 图像中 2D Anchor-free 目标检测器 CenterNet 的启发，研究者们将相同的概念扩展到 3D 目标检测器，提出了通过将 3D 目标视为 BEV 中的中心点的方法。</p><p>《PIXOR: Real-time 3D Object Detection from PointClouds》这篇文章使用了 Anchor-free 方法，目标在 BEV 中被视为 2D BBoxes。</p><p><strong>所有上述在 2D 空间中运行的 Anchor-Free网络中，均遵循 FCN 架构。</strong>2DBN 的输出 BEV 特征图通过共享或并行的 FCN 模块进行处理，用于分类、BBox 回归等。每个 FCN 块由连续的 2DConv 层组成。然后，对于每个任务，应用 1x1 卷积来生成置信度分数和 BBox 回归图。在《Afdet:anchor free one stage 3D objectdetection》文章的方法中，不再需要 NMS 后处理步骤，对于每个目标，仅预测一个中心点，因此仅会生成一个 3DBBox 候选框，这会节省计算资源。</p><h4 id="预测细化"><strong>3.3.2 预测细化</strong></h4><p>二阶段检测器会使用预测细化 (PR) 这一步骤。从检测器网络接收的 3DBBox 候选框是 PR 的输入，之后 PR 在细粒度级别对其进行采样并提取特征以提高分类置信度得分和明确 3DBBox 位置、大小和方向。PR 分为两大类，在 3D 空间中运行和在 2D 空间中运行。在 3D 空间中运行的 PR 根据表达形式上又会进一步分为三个子类别，即基于点的（point-based）、基于图形的（graph-based）和基于体素的（voxel-based）。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151040108.webp" alt="img" style="zoom: 25%;"></p><center>预测细化的子类别</center><p><strong>3D point-based PR</strong>利用点云的自然表达形式，从 3DBBox 候选框中采样固定数量的点。这种方式根据点的规范坐标、反射强度和学习的前景分数对点进行编码，而其他架构采用的是点与传感器的距离和学习的全局上下文特征对点进行编码。这些点之后被引入 PointNet 或 PointNet++ 架构，以改进类置信度分数和 3DBBox。</p><p><strong>3D graph-basedPR</strong>由两个模块组成：一个用于提取每个候选框 / 目标的局部特征（R-GCN），另一个用于提取每帧的全局特征（C-GCN）。R-GCN 模块对 3DBBox 候选框进行采样，并对点进行特征编码。接下来给定选定的点，通过 MRGCN 层构建和处理图像以输出局部特征向量。C-GCN 模块构建一个图，其中每个候选框 / 目标都被视为一个点，并使用从 R-GCN 学习的局部特征向量进行编码。然后，通过 EdgeConv 层处理该图，以学习所有候选框的全局特征。对于每个候选框，将来自 C-GCN 的全局特征与来自 R-GCN 的局部特征连接，然后引入两个完全连接的层以细化类置信度分数和 3DBBox。</p><h2 id="section4- 各类检测器的分析综述">Section4各类检测器的分析综述</h2><p>本部分讲述了 48 类最新的 3D 目标检测器，对其操作流程中每一个模块所用方式均进行了详细介绍、整理及分析，如下表所示。根据点云表达形式将其分为基于点的（35-42）、体素化的（1-24）、基于柱的（25-29）、基于投影的（30-34）、基于图像的（43）、双重表达形式（44-48）</p><figure><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211150941360.webp" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><h2 id="section-5- 数据集和评估指标"><strong>Section 5数据集和评估指标</strong></h2><p>公开可用的数据集可通过 3DBBox 的详细标签来训练基于 LiDAR 的 3D 目标检测器。</p><p>这些数据集有：①来自卡尔斯鲁厄理工学院的 KITTI 和最新的 KITTI-360 数据集、②来自 nuTonomy 的 nuScenes 数据集、③来自 Waymo 的 Waymo 开放数据集、④来自奥迪的 A2D2 数据集、⑤来自百度公司的 ApolloScape 数据集、⑥来自本田研究院的 H3D 数据集、⑦来自 LyftInc. 的 Lyft 数据集。上述数据集在某些属性上有所不同，例如标注目标的数量和目标类别等，但所有数据集都包含 LiDAR 传感器数据以及标注好的 3DBBoxes。下面介绍了三个（①②③）具有在线 3D 和 BEV 基准的开放数据集及其评估指标。</p><h3 id="kitti- 数据集">5.1 KITTI 数据集</h3><p>KITTI 数据集是最古老的自动驾驶应用数据集之一，由卡尔斯鲁厄理工学院和芝加哥丰田技术学院创建。它记录了德国卡尔斯鲁厄市白天的高速公路和农村地区的数据。数据集中包含：从两个正面高分辨率立体摄像系统（一种颜色和一种灰度）捕获的图像、从安装在汽车顶部的 VelodyneHDL-64ELiDAR 传感器捕获的 360°点云以及定位数据。KITTI 以每秒 10 帧 (fps) 的速率提供具有 LiDAR 点云图像的同步数据。</p><p>一个点由来自 LiDAR 传感器的 3D 坐标及其反射强度值的四维向量 [x,y,z,r] 编码。</p><p>对于 3D 和 BEV 目标检测任务，KITTI 数据集提供了一个固定的训练和测试集。目标被标记为八种不同的类别，但只有其中三个（汽车、行人和自行车）会被用于评估。此外，只有在相机视野内的物体（在图像中可见）才会用于评估。每个目标都以 3DBBox 的形式被标记，并由其中心坐标[x,y,z]、长、宽、高[l,w,h]（以米为单位）、航向和观察角度[α、θ]（以弧度为单位），遮挡和截断状态、对应类别等信息组成。目标最终会被分为简单、中等或困难类别，具体取决于其在 2D 图像中的相应大小（以像素为单位）及其截断状态。</p><p>对于 3D 和 BEV 目标检测任务，KITTI 使用均值平均精度 (mAP) 作为度量，并在联合交集 (IoU) 上有一个阈值。“汽车”类的 IoU 阈值设置为 0.7，“行人”和“自行车”类的 IoU 阈值设置为 0.5。3D 目标检测任务会使用预测值和地面实况 3DBBoxes 之间的 3D IoU；BEV 目标检测任务会使用预测值和地面实况 BEVBBoxes 之间的 2D IoU。如果 IoU 高于阈值，则将预测视为算法预测正确(TruePositive，TP)，否则视为算法预测错误(FalsePositive<strong>，</strong>FP)。</p><p>精确率 (p) 是指所有预测正确值 TP(NTP)占所有预测值（<em>NTotalDetections，</em>包括 TP 和 FP）的分数，即所有预测为正样本的样本中有多少是真正的正样本，计算公式为:</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151014636.png" alt="image-20221115101412582" style="zoom:33%;"></p><p>召回率 (r) 是指所有预测正确值 TP (NTP) 占所有真值 (NGroundTruth)的分数：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151014315.png" alt="image-20221115101435274" style="zoom:33%;"></p><p>Precision-Recall (P-R) 曲线是通过绘制不同 IoU阈值的精确率和召回率（分别在 y 轴和 x 轴上）构建。</p><p>平均精度（Average Precision）是由 P-R 曲线形成的面积。KITTI 使用基于 11 个召回率点计算 P-R 曲线的 mAP，在 2019 年第三季度后，改为使用 40 个召回率点插值，以更好地逼近 P-R 曲线。</p><p>平均精度 (mAP) 的计算方式是对所有类的平均精度 (AP) 进行平均来计算的。然而，该度量不能定义方向相似性（3DBBox 的前、后部是否正确）。因此，KITTI 还引入了平均方向相似度(AOS)，定义为：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151014973.png" alt="image-20221115101450929" style="zoom:33%;"></p><p>其中 N 是召回点的数量（2019 年第三季度前为 11，之后为 40），K 是召回子集（为 [0/11，1/11，2/11，...，11/11] 和 2019 年第三季度之后是[0/40,1/40,2/40,...,40/40]</p><p>方向相似度 s ∈ [0, 1] 是归一化余弦相似度，定义为：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151015670.png" alt="image-20221115101519625" style="zoom:33%;"></p><p>其中 D(r)是在召回率 r 下所有目标检测的集合，是第 i 个检测的预测方向与地面实况方向之间的角度差，如果检测 i 是 TP，则δi 设置为 1，否则δi 设置为 0.</p><h3 id="nuscenes- 数据集">5.2 NuScenes 数据集</h3><p>由 NuTonomy（新加坡企业）创建的 NuScenes 数据集是一个新推出的数据集，在波士顿和新加坡的四个不同地区在各种照明和天气条件下捕获的数据，可用于自动驾驶应用程序。它提供来自 32 束 LiDAR 传感器的 LiDAR 点云数据、来自 5 个不同 radar 传感器的 radar 数据以及来自六个不同 RGB 相机的相机数据。传感器放置在汽车相应位置上可覆盖 360°视野。</p><p>此外，激光雷达和摄像头传感器可以很好地同步，以提供 LiDAR 数据、radar 数据和 RGB 图像之间的数据对齐（具体时间同步文章可查看知乎文章：<a href="https://zhuanlan.zhihu.com/p/453871235">自动驾驶中的时间同步(上) -知乎(zhihu.com)</a>）。标记数据以 2Hz 的速率提供，但中间传感器帧也以高达 20Hz 的速率释放。</p><p>NuScenes 共有 23 个不同的目标类，但是它们之间存在严重的类不平衡。每个目标都用其类、属性（可见性、活动、姿势）和一个由其中心坐标 [x,y,z]、长度、宽度、高度[l,w,h] 及其偏航角θ编码的 3DBBox 进行标注。</p><p>对于 3D 目标检测任务，模型在 23 个类别中的 10 个类别中进行评估。引入了一个标量分数，即 nuScenes 检测分数(NDS)，由以下等式给出：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151015778.png" alt="image-20221115101549726" style="zoom:33%;"></p><p>AP 是指基于地平面上的 2D 中心距离 d 的匹配（超过 0.5、1.2 和 4m 阈值），而不是常用的重叠比(IoU)。AP 的计算为 P-R 曲线下的归一化区域，但是精度或召回率低于 10% 的点会被丢弃以降低噪声的影响。给定一组类别 C 和一组阈值距离值 D={0.5,1,2,4}，mAP 计算如下：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151016178.png" alt="image-20221115101600114" style="zoom:33%;"></p><p>算法预测正确（TP）的计算指标：如果一个预测的中心距离是位于 BEV 中相应地面实况 3DBBox 中心的 d=2m 距离阈值内，则该预测被视为 TP。TP 指标均为本地单位，还有一些指标被用于计算真阳性，包括：</p><ul><li>平均平移误差（ATE），即欧式中心距，单位为 BEV，单位为 m</li><li>平均尺度误差（ASE），它是方向和对齐后的 3DIoU 差异，计算方式为（1-IoU）</li><li>平均方向误差(AOE)，即预测与地面实况之间的最小偏航角差，单位为弧度</li><li>平均速度误差（AVE），它是绝对速度误差，作为 BEV 中速度差的 L2 范数，单位为 m/s</li><li>平均属性误差(AAE)，表示为 1 减去属性分类准确度，(1-acc)</li></ul><p>对于某些指标没有意义的某些类别（例如障碍和锥体的 AVE、AOE 和 AAE 指标），这些指标不予考虑。平均真阳性 (mTP) 指标计算公式为：</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151016753.png" alt="image-20221115101611711" style="zoom:33%;"></p><h3 id="waymo- 开放数据集">5.3 Waymo 开放数据集</h3><p>Waymo 开放数据集 (WOD) 是最新发布的自动驾驶数据集之一。它包括从 4 个短程 LiDAR 和 1 个中程 LiDAR 捕获的 LiDAR 数据以及从 5 个高分辨率 RGB 相机捕获的相机数据。该数据集非常多样化，因为它是一天中的不同时间在旧金山、山景城和凤凰城的郊区和城市地区所记录得到。在传感器和坐标系之间提供高质量的校准和转换。</p><p>LiDAR 数据以距离图像的表达形式提供。每个距离图像覆盖汽车周围的 360°视野。距离图像中的像素对应于 LiDAR 返回，并使用其距离、强度、伸长率、无标签区域、LiDAR 到相机投影信息以及捕获 LiDAR 点时的车辆姿态进行编码。“无标签区域”是指 LiDAR 点位于标签忽略的区域中。</p><p>对于 3D 目标检测任务，汽车周围 75m 半径内的目标会以 3D 边界框的形式标记为四个类别：车辆、行人、自行车、标志。每个 3DBBox 由其中心坐标[x,y,z]、长、宽、高[l,w,h]（以米为单位）、航向角θ（以弧度为单位）和其唯一的跟踪 ID 进行编码。</p><p>WOD 也使用常用的 AP 指标。然而，与 KITTI 用于计算 AP 的 40 点插值方法不同，WOD 将 AP 计算为 P-R 曲线下的面积</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151016278.png" alt="image-20221115101646232" style="zoom:33%;"></p><p>其中 p(r)是 P-R 曲线。</p><p>除了平均精度 (AP) 指标外，WOD 还引入了平均精度航向 (APH) 指标（用以包括航向信息）。与 AP 类似，APH 指标计算如下</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151017640.png" alt="image-20221115101707586" style="zoom:33%;"></p><p>其中 h(r)的计算类似于 p(r)，方法是通过航向精度 min 对每个真阳性进行加权。</p><p>关于检测 3D 目标的难度，WOD 定义了两个不同的级别，即 LEVEL 1 和 LEVEL2。LEVEL2 中分配的目标被认为是最难检测的目标。首先，所有无 LiDAR 点的目标会被忽略，不会分配到任一级别。其次，若一个目标的 LiDAR 点少于 6 个，或者如果人工标注员手动将目标分配给该类别，则该目标被分配到 LEVEL2。然后将其余目标分配给 LEVEL1。</p><p>为了实验的一致性，Waymo 团队为训练、验证和测试提供了固定的数据集。</p><h2 id="section-6- 讨论"><strong>Section 6 讨论</strong></h2><p>在本节中，将介绍每一类目标检测器的发现和关键见解，会考虑到这些目标检测器的操作流程、检测性能和效率。与第 4 节所定义的一样，这部分的分类依据是其输入的 LiDARSDR。</p><p>检测性能由第 5 节中详述的评估指标衡量。尽管这些指标可能略有不同（取决于数据集），<strong>侧重于测量在 3D 空间和 BEV 中检测目标类别的精度和召回率</strong>。根据每个数据集报告的推理时间评估效率。为了清楚起见，还说明了用于评估检测器的 GPU 硬件。</p><p>KITTI、nuScenes 和 Waymo 数据集的性能评估结果分别在表 2、表 3 和表 4-5 中所示。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211150949345.jpeg" alt="img" style="zoom:80%;"></p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211150959707.webp" alt="img" style="zoom:80%;"></p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211150959836.webp" alt="img" style="zoom:80%;"></p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211150950791.webp" alt="img" style="zoom:80%;"></p><p>总之，在本文比较研究中，对于给定的数据集，<strong>没有一个 3D 目标检测器在各个目标类别中都优于其他目标检测器</strong>。某些检测器在检测“汽车”类上表现更好，而其他检测器在检测“行人”或“自行车”类别上表现更好。此外，本文针对 KITTI 数据集评估了大多数检测器的性能（nuScenes 和 Waymo 尚未公开），这部分解释了 2019 年之前的 3D 目标检测器。</p><p>仅在 KITTI 上评估且仅针对“汽车”类的最新 3D 目标检测器进行评估，这不利于全方位评价整体性能和有效性，但由于许多 3D 目标检测器公开提供其源代码（如表 7 所示），可以通过评估KITTI 数据集的其余类以及其他可用数据集（如 nuScenes 和Waymo）的方法，可进一步了解方法的有效性。</p><p><img src="https://gitee.com/easonxu01/blogimg/raw/master/img/202211151004986.webp" alt="img" style="zoom: 33%;"></p><p>接下来，研究基于依赖于输入 LiDARSDR 的分类为每一类方法提供详细的性能分析。</p><h3 id="voxel-based- 目标检测器">6.1 Voxel-based 目标检测器</h3><p>从 section4 中给出 3D 目标检测器的图表中，可以看到，在大多数方法中，体素特征的提取大多会通过 VFE 模块及其变体或体素内点的平均值来进行。很少使用二进制占用值和手工制作的体素特征（通常是较旧的方法会使用）。体素化的数据通常由 SECOND 及其变体提出的 3DBN 处理。</p><p><strong>在 3DBN 模块之后，基于体素的目标检测器将数据表达形式从 3D 转换为 2D，从而产生 BEV。该策略在提高 3D 目标检测性能和缩短推理时间之间实现了平衡。</strong>仅使用 3DBN 模块的方法会有不错的检测性能，但推理时间很高，而仅使用 2DBN 的架构在 BEV 会兼具低推理时间和更高的检测性能。关于由 BEV 特征图馈送的相应 2DBN，文献中最常用的架构是 FPN，其变化主要与输入和输出特征图的数量有关。</p><p>检测器网络上，与 Anchor-basedRPN 相比，基于体素的检测器更倾向于使用 Anchor-free 网络，由于其计算高效的结构以及缺乏为每个目标类别定义和微调锚点大小。</p><p>根据 section4 中对操作流程的分析，显示正好有一半的 3D 目标检测器在点云表达形式中使用的是基于体素的。最新的方法已经提出了许多不同的架构，实现了大多数据集和目标类的最先进或顶级检测性能。上述三种方法中的共同策略是通过预测目标的部分或判别点及其目标内空间位置，对目标的 3D 几何信息进行有效编码。如表 2 所示，大多数基于体素的目标检测器是一阶段段检测器，这表明单次推理通过导致可接受的性能以及低推理时间。还有使用任一体素的两阶段检测器或基于点的网络来提取目标 3D 形状的细粒度表示并细化预测的 3DBBox。结果，在略微增加的推理时间下观察到改进的检测性能。然而，最近的检测器在其第二阶段提出了一种基于混合体素 / 点的网络，既保持了一阶段检测器的低推理时间，又实现了顶级性能。</p><h3 id="pillar-based- 目标检测器">6.2 Pillar-based 目标检测器</h3><p>在 Pillar-based3D 目标检测器中，柱（pillar）的特征完全通过基于点的网络提取，如 VFE 模块及其变体。接下来，采用 BEV 特征图的构建，这为使用 2DBN 模块奠定了基础。这部分所有的目标检测器中，2DBN 模块都由 FPN 架构组成，其变化主要与输入和输出特征图的数量有关。大多数方法使用 Anchor-basedRPN 进行目标检测。同时，与 Voxel-based目标检测器相似的是，为了效率和简单性，也存在 Anchor-Free网络的趋势。此外，<strong>所有 Pillar-based 的目标检测器都是一阶段检测器</strong>。</p><p>与所有方法相比，Pillar-based目标检测器在 KITTI 数据集中所有“简单”和“中等”级别的目标类别上均取得了不错的检测性能，但在“困难”级别上略逊一筹。此外，在更复杂和要求更高的 nuScenes 和 Waymo 数据集中，Pillar-based 检测器的性能比 Voxel-based 检测器效果较差，即使对于“简单”和“中等”的情况也是如此。</p><p>研究认为这是因为不能有效编码目标的 3D 结构和几何信息，尤其是在远处或被遮挡的情况下。原因可能是 Point-based 网络的局限性，即用于提取柱特征向量的轻量级 VFE，以及缺乏 3DBN 模块的原因。</p><p>通过比较 PointPillars 和 SECOND 在 KITTI 和 Waymo 数据集中的性能来论证这一假设。两者结构相似，主要区别在于：PointPillars 使用轻量级 VFE 模块来提取柱状特征并构建 BEV 特征图，SECOND 通过 3DBN 构建 BEV 特征图。结果发现，PointPillars 在 KITTI 数据集上的性能略有提高，但 SECOND 在 Waymo 数据集上的性能大大优于 PointPillars。</p><p><strong>就计算效率而言，Pillar-based检测器是最有效的检测器，因为与其他类检测器相比，他们实现了最低的推理时间。</strong></p><h3 id="projection-in-bev- 目标检测器">6.3. Projection in BEV目标检测器</h3><p>对 Projection in BEV3D 目标检测器而言，其采用手工制作的特征来构建 BEV 特征图，并在架构的其余部分使用典型的 2D 目标检测架构，例如 Faster-RCNN，主要 2DBN 的架构中有些不同。</p><p>事实表明，这一类别表现出总体上降低的检测性能以及增加的推理时间。此外，Pillar-based3D 目标检测器出现以来，这一类别对研究界的使用吸引力降低。</p><h3 id="projection-in-fv 目标检测器">6.4. Projection in FV 目标检测器</h3><p>对于 Projection in FV3D 目标检测器，距离图像像素编码方式采用手工制作的特征，然后引入 2DBN 进行特征提取。这个类别中只有两种方法：LaserNet 和 Range-RCNN。</p><p>这两种方法仅在 KITTI 数据集的“汽车”类中进行评估，其中一种仅用于 BEV 检测任务。这类方式的推理时间很短，但这一特定类别并没有充分激发研究界的兴趣。造成这种情况的一个潜在原因是 FV 距离图像无法反映物体的真实比例。为了解决这个问题，Range-RCNN 在 FV 距离图像中执行特征提取后，后续预测细化部分中它对检测部分的 BEV 图进行了对应。</p><h3 id="point-based- 目标检测器">6.5. Point-based 目标检测器</h3><p>Point-based3D 目标检测器仅在 3D 空间中运行，它们主要使用 encoder/decoder 架构的 PointNet++ 作为其 3DBN 模块。与学习到的高维特征点一起，执行前景 / 背景点分割。该分割信息用于指导 Anchor-Free 网络，以输出每个点的目标候选框。大多数 Point-based3D 目标检测器由两个阶段组成，其中大多数在第二阶段遵循 Point-based的点云表达形式。但事实证明在预测细化的第二阶段使用 voxel-based 的表达形式可提高检测性能并减少推理时间。相反，使用 graph-based 的点云表达形式的观察结果为检测性能的边际增加以及推理时间的显著增加。</p><p>最近一种一阶段检测器引入了 PointNet++encoder 架构的新 3DBN 模块，在检测性能和计算效率方面产生了一种简化且整体更有前景的结构，可与顶级的 voxel-based检测器相媲美。</p><p>如表 2 所示，大多数 point-based检测器略微适用于实时应用。由于这个限制，最近有文章研究了该类检测器的改进。特别是 3DSSD 目标检测器采用了高效的 3DBN 并已在 nuScenes 和数据集中进行了评估。而 StarNet 目标检测器通过处理感兴趣区域而不是立刻处理点云来弥补 point-based检测器的缺点，这一检测器也在 Waymo 中进行了评估。</p><h3 id="graph-based- 目标检测器">6.6 Graph-based 目标检测器</h3><p>对于 Graph-based目标检测器，文献中只报道了一项——Point-GNN。这种方法一旦构建了点云的图表示，就会连续应用图神经网络，且在不使用其他模块（如 3DBN、2DBN 等）的情况下进行端到端的 Graph-based的目标检测。</p><p>如表 2 所示，KITTI 数据集所报告的 Point-GNN 的需要花费的高推理时间可能是其吸引力降低的主要原因，尤其是对于自动驾驶这种对推理时间要求较高的应用而言。但从检测性能非常令人满意且总体上很有希望而言，可以看出 Graph-based 检测器的研究潜力。</p><h3 id="双重点云表达目标检测器">6.7 双重点云表达目标检测器</h3><p>双重点云表达形式的目标检测器存在两种方法。</p><p>第一种方法，构建两个不同的点云表达形式以提取依赖于视图的特征，然后将其融合从而产生逐点的多视图特征表示。</p><p>第二种方法，第一个点云表达形式（即 voxel-based）用于提取多尺度特征向量和 3DBBox 候选框，第二个点云表达形式（即 point-based）用于进一步处理和聚合多尺度体素特征向量到少量关键点以辅助 3DBBox 细化。双重点云表达目标检测器不遵循与其架构有关的特定模式，而是基于其点云表达形式使用相应的操作模块，如 3DBN/2DBN 等。</p><p>这两种方法都旨在更有效地学习和编码目标的 3D 结构信息。学习多视图特征的第一种方法可以整体提高检测性能，但是与学习多尺度特征的第二种方法相比较差差，因为 PV-RCNNv1、PV-RCNNv2 的检测器实现了最先进的检测性能，适用于 KITTI 和 Waymo 数据集中的大多数课程和难度级别。与 voxel-based检测器相比，所有双重点云表达检测器的推理时间（Waymo 的 PV-RCNNv1 除外）略有增加，但仍适用于实时应用。</p><h3 id="注意力机制">6.8 注意力机制</h3><p><strong>注意力（attention）或自我注意(selfattention)可提高 3D 目标检测器的整体性能。</strong>特别是 TA-Net 中的工作实现了三重注意（TA）模块用以在提取柱特征向量期间进行局部注意。</p><p>为了在特征向量中提供全局 attention，为 3D 目标检测器实现了自关注模块。attention 模块在两个不同的网络下实现，即完全自我注意（FullSelf Attention ，FSA）和可变形自我注意（Deformable Self Attention，DSA），它们可以插入现有的 3D 目标检测器中提高其整体性能。这种改进已在 Point-Pillars、SECOND、Point-RCNN、PV-RCNNv1 中得到证明。</p><h2 id="section-7. 未来研究趋势和未解决问题">Section7. 未来研究趋势和未解决问题</h2><p>本节们将介绍对 3D目标检测在自动驾驶应用中的未来趋势、研究潜力和对未解决问题的见解。</p><h3 id="在嵌入式系统中的应用">7.1 在嵌入式系统中的应用</h3><p>大多数文献报告了以上检测器对 GPU 硬件（通常在台式计算机中）的推理时间，在嵌入式系统中的边缘计算设备情况容易被忽略。但嵌入式系统是自动驾驶汽车或移动机器人必不可少的硬件。此外，很少有文献报道这些方法在网络大小和内存分配方面的复杂性。</p><p>某些检测器（如 Pillar-based 检测器）专注于通过采用简单高效的架构来对嵌入式系统进行计算友好，从而减少网络参数的数量，或者通过专门设计的 GPU 推理库（如英伟达的 TensorRT）进一步优化其架构。然而，这两种方法也并没有在边缘计算设备上进行测试或评估。此外，这些方法的能耗（嵌入式系统最重要的因素之一，尤其是对于自动驾驶汽车和移动机器人）从未被视为关键约束或作为基准报告。受《Deeplearning inference at the edge for mobile and aerialrobotics》一文中在 Nvidia JetsonTX1 上对用于语义分割推理的深度学习方法进行了比较研究和基准测试。受其启发，《Energy-awaredesign of vision-based autonomous tracking and landing of auav》一文也根据检测器在 Nvidia JetsonNano 上的服务质量功能作为深度学习 2D 目标检测器的能耗评估。类似的用于嵌入式系统中基于 LiDAR 的 3D 目标检测器的比较和能量分析研究具有较大的研究潜力，如表 7 所示的公开可用的检测器代码将进一步有助于实现这一研究尝试。</p><h3 id="迈向高效的混合网络">7.2 迈向高效的混合网络</h3><p>PV-RCNNv2 和 Voxel-RCNN 工作的最新进展专注于用更高效的体素启发式来替代 point-based 网络中某些计算成本高昂的操作（例如 PointNet++ 中的集合抽象和球查询操作），同时仍保留 point-based 网络的其余部分不变。这样的解决方案促使混合网络的出现，其充分利用了两者优点：提高检测性能和缩短推理时间。类似的方法也可以应用于图神经网络，以减少图神经网络的计算负担。因此，识别现有架构中计算效率低下的瓶颈并通过混合方法改进这一方面存在研究潜力。</p><p>大多数 3D 目标检测器使用单个的点云表达，最近一些方法使用双重点云表达来提取更丰富和更具辨别力的特征向量。在同一检测器中使用更多点云表达的唯一限制是架构的推理时间。混合网络旨在进一步减少检测器的推理时间，这有助于使用额外的第三个甚至第四个点云表达来学习更多的判别特征。</p><h3 id="lidar- 点云的稀疏性">7.3 LiDAR 点云的稀疏性</h3><p>点云固有的稀疏性引起了研究界的兴趣，特别是对于 3D 目标补全和形状生成架构。在用于自动驾驶的 3D 目标检测中，目标和形状补全技术已被用作训练期间的预处理步骤，以通过域适应策略关联和学习稳健的特征。然而，在 LiDAR 点云的推理过程中，3D 目标检测器尚未使用目标补全和形状生成架构，这可能会提高检测性能。</p><h3 id="自监督学习">7.4 自监督学习</h3><p>在 WS3D 的工作中，现有的二阶段目标检测器（即 Point-RCNN）被用作实现和测试弱监督训练方法的主干。研究者手动构建弱注释数据并将它们用于训练检测器的第一阶段，而详细的标注数据用于训练第二阶段。到目前为止，这项工作是自动驾驶应用中基于 LiDAR 的 3D 目标检测器的自我监督学习最接近的近似值。由于难以获得详细的标注数据，3D 目标检测器的自监督和半监督学习具有很大的研究潜力。</p><h3 id="复杂现实场景的性能评估">7.5 复杂现实场景的性能评估</h3><p>目前所提出的 3D 目标检测器只是在三个公开可用数据集（即 KITTI、nuScenes 和 Waymo）中的一个或多个场景中进行评估。然而，与更复杂和更现实的 3D 目标检测场景相比，这三个数据集以及表 1 中显示的其余数据集都表现出局限性。这些限制包括场景多样性的降低、噪声数据的缺乏和目标类别的数量少。</p><p><strong>场景多样性：</strong>所有公开可用的数据集都包含来自城市或高速公路区域的场景，<strong>这些场景几乎是平坦的</strong>，具有边缘地面倾斜度。因此，所有 3D 目标检测器旨在为每个物体预测 4 个自由度(Degreesof Freedom ，DoF)的 3DBBox 姿势，它代表 x、y、z 位置和偏航角方向。对于自动驾驶中更具挑战性的 3D 目标检测案例，必须包括“<strong>目标并不总是与自车在同一平面内</strong>”的场景，即在具有不同地面倾斜度的交叉道路的情况。这样的场景在城市和农村都可能出现。在这种苛刻的场景中，当前对 4-DoF 姿态的 3DBBox 预测可能不足，因此可能导致 3D 目标检测器将预测的姿态从 4-DoF 扩展到 5-DoF，包括 3DBBox 的俯仰角。</p><p><strong>噪声数据：雾、雨和雪等不利天气条件 </strong> 是在激光雷达传感器测量中引入额外噪声的主要自然现象，因为在这种天气条件下激光雷达传感器发射的激光束可能会发生折射。然而，nuScenes 和 Waymo 数据集已部分解决了基准数据集中出现的此类噪声。除自然现象外，<strong>多个激光雷达传感器同时发射也可能会引入额外的干扰噪声</strong>。这不是指单个车辆的多个 LiDAR 传感器（自车安装的 LiDAR 传感器配置是已知的），而是指场景中的其他车辆也使用 LiDAR 传感器。目前所有公开可用的数据集都在自车是唯一安装了 LiDAR 传感器 / 传感器的场景中记录的。因此，上述情况下 LiDAR 传感器测量中可能会引入额外的噪声。恶劣的天气条件和来自其他 LiDAR 传感器的干扰都会引出对补偿噪声数据的研究，即通过某些预处理算法在将点云送至现有 3D 目标检测器之前过滤掉噪声数据。</p><p><strong>数据集目标类别：</strong>当前标准测试数据集针对一定数量的目标类别评估 3D 目标检测器的性能。对于大多数据集，目标类的数量为三个，nuScenes 包含十类。在现实场景中，要检测的目标类别的数量可能会进一步增加以反映真实的上下文。此外，数据集的类分布不均匀会导致训练过程中出现类不平衡问题，随着目标类数量的增加，这种问题变得非常严重。MEGVII 检测器解决了 nuScenes 数据集的类别不平衡问题。然而，更有效的策略研究仍有研究潜力，特别是对于那些使用 Anchor-Free网络的策略。此外，迁移学习还可用于重新训练 3D 目标检测器以适应新的目标类别，基于少量且类别平衡的标记数据。这种策略也可以与自我监督学习结合使用。</p><h2 id="section-8- 结论">Section 8 结论</h2><p>在过去几年中，由于深度学习架构、可用 LiDAR 的进步及其在自动驾驶商业应用中的潜力。仅使用 LiDAR 点云数据的 3D 目标检测已成为一个活跃的研究领域。</p><p>本文对基于 LiDAR 的 3D 目标检测器的操作流程进行了分析，并通过统一的框架展示和讨论了各操作模块，以建立各检测器间的共同点。检测器通过上述统一框架进行分类和单独呈现。此外，根据自动驾驶应用的三个开放数据集的标准和评估指标来研究检测器性能。总结了研究发现和构成未来工作研究潜力的关键要素。这项工作是目前文献中最完整的，旨在为每种方法的优缺点提供有用的见解。</p>]]></content:encoded>
      
      
      <category domain="http://xuzikun.com/categories/3D-Detection/">3D-Detection</category>
      
      
      <category domain="http://xuzikun.com/tags/3D-Detection/">3D-Detection</category>
      
      <category domain="http://xuzikun.com/tags/Lidar/">Lidar</category>
      
      
      <comments>http://xuzikun.com/2022/11/15/%E3%80%8AA%20comprehensive%20survey%20of%20LIDAR-based%203D%20object%20detection%20methods%20with%20deep%20learning%20for%20autonomous%20driving%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hello World</title>
      <link>http://xuzikun.com/2022/11/13/helloworld/</link>
      <guid>http://xuzikun.com/2022/11/13/helloworld/</guid>
      <pubDate>Sun, 13 Nov 2022 08:51:26 GMT</pubDate>
      
        
        
      <description>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;欢迎你&quot;&gt;欢迎你！&lt;/h1&gt;
&lt;p&gt;虽然现在这里还是 &lt;stro</description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="欢迎你">欢迎你！</h1><p>虽然现在这里还是 <strong style="color:#00b0f0;"> 冷冷清清</strong>，</p><p>但是之后我会建起一片 <strong style="color:#00b050;"> 茂密的森林</strong>！</p>]]></content:encoded>
      
      
      <category domain="http://xuzikun.com/categories/%E6%97%A5%E5%B8%B8/">日常</category>
      
      
      <category domain="http://xuzikun.com/tags/%E6%AC%A2%E8%BF%8E/">欢迎</category>
      
      
      <comments>http://xuzikun.com/2022/11/13/helloworld/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
